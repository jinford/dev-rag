# 要件定義書
**システム名：社内リポジトリ向け RAG 基盤および Wiki 自動生成システム**

---

## 1. 概要

本システムは、社内の複数の情報ソース（Git リポジトリ、Confluence、PDF、Redmine等）を対象に、

- テキストをチャンク（小さな単位）に分割し、
- OpenAI Embeddings を用いてベクトル化し、
- Postgres + pgvector に保存・検索できる状態を作り、
- そのインデックスを活用して Markdown 形式の Wiki を自動生成する

ことを目的とした **RAG（Retrieval-Augmented Generation）基盤**である。

**注:** 初期フェーズでは Git リポジトリのみをサポートするが、データモデルは複数の情報ソースに対応できる汎用的な設計とする。

初期フェーズでは「RAG チャット機能」は実装しないが、将来的に

- 外部 LLM クライアント（例：Claude Desktop / 各種エディタ）から利用される **MCP（Model Context Protocol）サーバ**
- コード・設計に対する RAG チャット API

を実装できるような基盤構造を前提とする。

---

## 2. 背景

### 2.1 現状の課題

- ソースコード、設計ドキュメント、運用手順書などの技術情報が Git リポジトリや各種ツールに分散しており、「目的の情報にたどり着くまでに時間がかかる」。
- 開発者は IDE の全文検索や `grep` による検索結果を自力で読み解く必要があり、「どのコードがどの設計と対応しているか」を理解する負荷が高い。
- Wiki やドキュメントは手動で更新されることが多く、コードとの乖離が生じやすい。

### 2.2 解決したいこと

- 「コードや設計を横断して意味ベースで検索できるインデックス」を持つ。
- そのインデックスを利用して、リポジトリごとの技術 Wiki を自動生成し、コードとドキュメントの乖離を減らす。
- 将来的に、RAG チャットや MCP サーバとして拡張可能な形で基盤を整えておく。

---

## 3. 目的

本システムの目的は次の通りである。

1. **技術ナレッジの検索性向上**
   コード・設計・ドキュメントをベクトル化して Postgres に集約し、
   将来的に RAG チャットや意味検索で使える基盤を構築する。

2. **Wiki 自動生成によるドキュメント整備の省力化**
   リポジトリの構造やコードをもとに、システム概要やモジュール構成、メッセージフローなどを Markdown で生成することで、
   ドキュメント作成の負担を減らす。

3. **MCP サーバ化を見据えた検索 API の共通化**
   将来的に MCP サーバ実装で再利用できるよう、ベクトル検索ロジックを共通のインターフェースで提供する。

---

## 4. 用語定義

- **RAG（Retrieval-Augmented Generation）**
  LLM が回答を生成する前に、外部データソースから関連情報（コンテキスト）を検索し、
  その情報をプロンプトに追加して回答の質を高める手法。

- **Embedding（埋め込み）**
  テキストを高次元の数値ベクトル（例：長さ 1536 の float 配列）に変換したもの。
  ベクトル同士の距離を計算することで、「意味の近さ」を数値的に扱える。

- **OpenAI Embeddings**
  OpenAI が提供する Embedding モデル（例：`text-embedding-3-small`）。
  テキストを Embedding ベクトルに変換する API を提供する。

- **ベクトルストア / ベクトル DB**
  Embedding ベクトルを保存し、類似ベクトル検索（KNN 検索）を行うためのストア。
  本システムでは PostgreSQL + pgvector 拡張を用いる。

- **MCP（Model Context Protocol）**
  LLM クライアント（IDE, デスクトップアプリなど）と外部ツール（サーバ）間で、
  検索やアクションを呼び出すための標準プロトコル。
  本システムは将来、MCP サーバとしてベクトル検索ツールを提供することを想定する。

- **チャンク（Chunk）**
  ファイルを小さな単位（数十行〜百数十行程度）に分割したテキストの単位。
  Embedding はチャンク単位で作成される。

- **スナップショット（Snapshot）**
  特定のコミット（またはブランチの HEAD）時点のリポジトリ状態。

---

## 5. システム範囲

### 5.1 本システムがカバーする範囲

1. **インデックス基盤**
   - 情報ソースからのデータ取得（初期フェーズは Git リポジトリのみ）
     - Git リポジトリのクローン／更新
     - 将来的に Confluence、PDF、Redmine 等のサポートを追加
   - ファイル一覧の取得
   - ファイルのチャンク化
   - チャンクテキストの Embedding 生成
   - Embedding を Postgres + pgvector に保存・更新

2. **Wiki 自動生成**
   - 対象リポジトリとスナップショットを指定して、インデックスを参照
   - ページ種別ごとに関連チャンクを検索
   - LLM により Markdown 形式のページ（Mermaid コード含む）を生成
   - ローカルディレクトリに Markdown ファイルとして出力

3. **将来の MCP サーバ化を見据えた検索インターフェース**
   - ベクトル検索を行う内部 API（Go の抽象インターフェース）の提供
   - MCP サーバから再利用できるような検索オプションの設計

### 5.2 本システムがカバーしない範囲（初期フェーズ）

- RAG チャット用の Web UI や API。
- LLM とユーザとの対話管理（セッション管理）機能。
- Mermaid 図のレンダリング（表示）は、既存の Wiki ツールやビューアに任せる。
- OpenAI の Vector Store / File Search など、OpenAI 側のベクトルストア機能は利用しない。

---

## 6. 利用者・ステークホルダー

- **開発者**
  - 自分の担当するサービスやモジュールの構造理解、影響範囲の把握に利用。
  - コード変更時に Wiki を更新するために CLI を実行。

---

## 7. 利用シナリオ

### 7.1 インデックス作成（開発者ローカル）

1. 開発者がローカル環境に本システムの CLI をインストールする。
2. CLI でリポジトリをインデックス化する。
   - リポジトリURL、ブランチ/タグを指定
   - 必要に応じてリポジトリ名を明示的に指定
3. CLI は内部で Git をクローンし、ファイルをチャンク化し、OpenAI Embeddings API でベクトルを取得し、Postgres に保存する。
4. リポジトリ情報は自動的に登録・更新される。
5. 以後、Wiki 生成や検索機能はこのインデックスを参照する。

### 7.2 インデックス更新（CI 上での差分更新）

1. GitLab CI で main ブランチへのマージを検知した際にパイプラインを起動する。
2. パイプラインから dev-rag サーバの REST API (`POST /api/v1/sources/index`) を呼び出し、該当ソースのインデックス更新をトリガーする。
   ```bash
   curl -X POST http://devrag.example.com:8080/api/v1/sources/index \
     -H "Authorization: Bearer $DEVRAG_API_TOKEN" \
     -H "Content-Type: application/json" \
     -d '{
       "sourceName": "backend-api",
       "ref": "main",
       "commitHash": "'$CI_COMMIT_SHA'",
       "generateWiki": true
     }'
   ```
3. dev-rag サーバは非同期でインデックス処理を実行する。
   - 差分更新モードでは、前回のインデックスと比較して変更されたファイルのみを処理
   - 前回のインデックスが存在しない場合は、自動的にフルインデックスを実行
   - `generateWiki: true` が指定されている場合、インデックス完了後に自動的に Wiki を生成する
4. API は即座にジョブ ID を返却し、CI パイプラインはすぐに完了する。
5. インデックス処理とWiki生成はサーバ側でバックグラウンドで継続される。

### 7.3 Wiki 自動生成

1. 開発者が CLI または REST API で Wiki 生成を実行する。
   - CLI: `dev-rag wiki generate --product ecommerce`
   - API: `POST /api/v1/products/wiki`（リクエストボディで `productName` を指定）
2. システムは Postgres からプロダクトに属する各ソースの最新インデックス済みスナップショットのチャンクを検索する。
   - **Gitソースの場合**: `sources.metadata.default_branch` で指定されたブランチ（未指定時は `main`）が `git_refs` で指すスナップショットを使用
   - **Git以外のソースの場合**: 該当ソースの `indexed=true` のスナップショットを `indexed_at` 降順で取得し、最新を使用
3. ページ種別（概要、アーキテクチャ、機能詳細など）ごとに関連するチャンクを取得し、LLM に渡して Markdown を生成する。
4. `/var/lib/dev-rag/wikis/<プロダクト名>/` ディレクトリにファイルとして出力する。
5. 生成されるページには以下を含む：
   - プロダクト概要と目次
   - 全体アーキテクチャ・依存関係・メッセージフロー
   - 機能別の詳細説明
   - Mermaid ダイアグラム（推奨）

### 7.4 Wiki 閲覧

1. 開発者はブラウザで dev-rag wiki-viewer にアクセスする（例：http://localhost:3000）。
2. ダッシュボードには、インデックス済みのプロダクト一覧が表示される。
3. プロダクトを選択すると、生成された Wiki が表示される。
4. Wiki は Markdown がレンダリングされ、Mermaid 図も表示される。
5. サイドバーから異なるページ（index.md, architecture.md, features/ 配下など）に遷移できる。
6. 「Wiki を再生成」ボタンをクリックすると、バックグラウンドで Wiki が更新される（各ソースの最新スナップショットを使用）。

### 7.5 将来の MCP サーバ利用（参考）

※初期フェーズでは実装しないが、利用イメージのみ定義しておく。

1. 開発者が MCP 対応の LLM クライアント（例：Claude Desktop）から、`rag-search` ツールを呼び出す。
2. MCP サーバがクエリ・オプションを受け取り、Postgres + pgvector に対してベクトル検索を実行する。
3. MCP サーバが検索結果（ファイルパス、行番号、チャンクテキスト）を JSON として返す。
4. LLM クライアントはこの結果をもとに回答を生成し、ユーザに説明する。

---

## 8. 機能要件

### 8.1 プロダクト管理機能

- システムは、プロダクト（複数のソースをまとめる単位）を登録・更新できなければならない。
- 各プロダクトには一意な ID が付与される。
- プロダクトには、名前と説明を登録できる。
- プロダクトは複数のソースを持つことができる（1対多関係、1つのソースは1つのプロダクトにのみ所属）。
- **使用例:** ECサイトプロダクト = バックエンドGit + フロントエンドGit + インフラGit + Confluence + Redmine

### 8.2 ソース管理機能

- システムは、対象とする情報ソース（Git、Confluence、Redmine等）の情報を登録・更新できなければならない。
- 各ソースには一意な ID が付与される。
- ソース種別（source_type）により、以下のタイプをサポートする：
  - `git`: Gitリポジトリ
  - `confluence`: Confluenceスペース
  - `redmine`: Redmineプロジェクト
  - `local`: ローカルファイル
- ソースタイプ固有の情報（URL、認証情報等）は metadata（JSONB）カラムに格納する。
- ソース情報は PostgreSQL 上の専用テーブルに永続化し、CLI から参照・更新できるようにする。
- 1つのソースは1つのプロダクトにのみ所属する（1対多関係、product_id カラムで管理）。
- **初期フェーズでは Git リポジトリのみを実装する。**
- Git 認証情報は、常駐プロセス（HTTPサーバー）がアクセス可能な場所に配置する。
  - SSH鍵を `/etc/dev-rag/ssh/id_rsa` に配置し、設定ファイル (`/etc/dev-rag/config.yaml`) で鍵パスを指定する。
  - パーミッション `0600`（所有者のみ読み書き可能）で保護し、サービス実行ユーザー（例：`devrag`）が所有する。
  - 社内Gitサーバー専用のSSH鍵を使用することを推奨する。

### 8.3 スナップショット管理機能

- システムは、`ソース ID + バージョン識別子` の組み合わせでスナップショットを管理しなければならない。
- バージョン識別子は、ソースタイプにより以下のように扱う：
  - Git: コミットハッシュ（SHA-1、40文字）
  - Confluence: ページバージョン番号
  - PDF: ファイルハッシュ（SHA-256）
  - Notion: 最終更新タイムスタンプ
- 各スナップショットに対して、以下の情報を保持する。
  - 対象となるソース ID
  - バージョン識別子（version_identifier）
  - インデックス済みかどうか（boolean）
  - インデックス完了日時
- 同じバージョン識別子に対して複数回インデックスを実行した場合も、重複したスナップショットは作成せず、既存レコードを更新する。
- **Gitソースの場合、別途 `git_refs` テーブルで参照（ブランチ、タグ）とスナップショットの紐付けを管理する。**
  - 1つのブランチ/タグは1つのスナップショットを指す
  - 同じコミット（スナップショット）を複数の参照（main と v1.0.0）で指すことが可能
- **初期フェーズでは Git のコミットハッシュのみを扱う。**

### 8.4 ファイル・チャンク管理機能

- システムはスナップショット内のファイル・ドキュメント一覧を取得し、以下の情報を保存できなければならない。
  - ファイルパス（またはドキュメント識別子）
  - ファイルサイズ
  - 言語種別（コードの場合、簡易な判定でよい）
  - ファイル内容のハッシュ
  - コンテンツ種別（`code` / `doc` / `wiki`）
- システムは各ファイルをチャンク化し、チャンクごとに以下を保存する。
  - ファイル ID
  - チャンクの序数（ordinal）
  - 開始行・終了行
  - チャンクのテキスト内容
  - チャンク内容のハッシュ
  - トークン数（必要であれば）
- ファイルやチャンクのハッシュは、差分インデックス時に「変更の有無」を判定するために使用される。
- チャンク化の目標サイズは 1 チャンクあたり約 800 トークン（目安 2,500〜3,000 文字）とし、前後 200 トークン相当のオーバーラップを設ける。
- **インデックス対象外ファイルの除外ルール:**
  1. `.gitignore` のパターンを先に適用（Git管理外ファイルを除外）
  2. `.devragignore` のパターンを追加で適用（RAG特有の除外）
  3. 除外優先順位: .gitignore → .devragignore
  4. `.devragignore` ファイルはリポジトリルートに配置し、Gitignore形式のパターンを記述
  5. `.devragignore` ファイル例:
     ```
     # .gitignore に加えて除外するパターン
     node_modules/
     dist/
     *.log
     .git/
     ```

### 8.5 Embedding 生成・保存機能

- システムは、各チャンクのテキストを OpenAI Embeddings API に送信し、ベクトルを取得できなければならない。
- Embedding のモデルは `text-embedding-3-small` などを利用し、次元数（例：1536）をシステム側で固定して扱う。
- 取得したベクトルは PostgreSQL + pgvector の `vector(N)` 型として保存する。
- Embedding はチャンクと 1 対 1 に対応し、チャンク ID を主キーとして保存する。
- Embedding の保存先は PostgreSQL のみとし、SQLite やローカルファイルなどの別 DB には保存しない。

### 8.6 差分インデックス機能

- システムは、既存のスナップショット情報とファイルハッシュを利用して、
  新規追加または内容変更されたファイルのみを再インデックスできなければならない。
- 差分インデックス時の動作は、以下の通りとする。
  1. 対象スナップショットの既存ファイル情報を取得する。
  2. Git から最新の対象コミットを取得し、ファイル一覧とハッシュを計算する。
  3. 新規ファイルは追加、削除されたファイルは削除、ハッシュが変わったファイルはチャンクと Embedding を再生成する。
- デフォルトでは、同一ソース・同一参照（Gitの場合はブランチやタグ）で最後に成功したスナップショットとの比較を行い、差分があれば差分更新、なければスキップする。
  - Gitの場合: `git_refs` テーブルで該当するブランチ/タグが指す最新スナップショットと比較
  - Git以外の場合: 該当ソースの最新スナップショットと比較
- 前回のスナップショットが存在しない場合（初回実行時）は、自動的にフルインデックスを実行する。
- 必要に応じて、強制的にフルインデックスを実行する手段を提供する。
- ファイルリネームは「旧ファイル削除＋新ファイル追加」として扱い、Embedding を再生成する。
- 同一ソースかつ同一参照を対象とするインデックス処理は、PostgreSQL のアドバイザリロック等を用いて排他制御し、同時実行時はジョブを順番待ちさせる。

### 8.7 ベクトル検索機能（内部 API）

- システムは、以下の条件を入力としてベクトル検索を実行できなければならない。
  - プロダクト名またはソース名
  - 検索クエリ文字列
  - 返却件数（limit）
  - パス prefix（任意）
  - コンテンツタイプ（任意、MIMEタイプ: text/x-go, text/markdown等）
  - 前後コンテキストを含めるかどうか、およびそのサイズ
- 検索対象は常に各ソースの最新インデックス済みスナップショット
- システムは上記入力をもとに、以下の処理を行う。
  1. 検索クエリを Embedding し、クエリベクトルを得る。
  2. プロダクトまたはソースに属する最新インデックス済みスナップショットを特定する。
  3. フィルタ条件で対象チャンクを制限する。
  4. pgvector の距離演算（cosine 等）を用いてクエリベクトルとの距離を計算し、類似度の高いチャンクを上位から取得する。
  5. オプションに応じて、ヒットチャンクの前後チャンクも取得し、コンテキストとして返却する。
- 戻り値には、少なくとも次の情報を含める。
  - ファイルパス
  - 開始行・終了行
  - チャンクテキスト
  - スコア
- スコアは `score = 1 - cosine_distance` として 0〜1 に正規化し、デフォルトでスコア降順に返す。
- 前後コンテキストはそれぞれ最大 1 チャンクを既定値とし、0〜3 の範囲に設定可能とする。
- 本フェーズでは内部APIとして実装のみを提供し、RPC/HTTP エンドポイントは提供しない。

### 8.8 Wiki 自動生成機能

- システムは、**プロダクト単位**で Wiki を Markdown 形式で生成できなければならない。
- **プロダクト単位のWiki生成:**
  - プロダクトに紐付く全ソース（バックエンド、フロントエンド、Confluence、Redmine等）の情報を統合してWikiを生成
  - プロダクト全体のアーキテクチャ、依存関係、メッセージフローを説明
  - 各ソースから取得したチャンクを横断的に検索して、プロダクト全体の理解を促進
- 生成するページ構成:
  - `index.md`: プロダクト概要、目次、主要コンポーネントサマリー
  - `architecture.md`: システム全体構成、依存関係、メッセージフローを説明し、Mermaid 図（例：flowchart, sequence）を最低 1 つ含む
  - `features/<feature-name>.md`: 各機能ごとの責務、主なファイルを説明し、可能な限り機能内のフローを表した Mermaid 図を挿入
- 各ページは、あらかじめ定義された「疑似クエリ」と検索対象（ディレクトリやソース種別）に基づいてチャンクを取得し、LLM に渡して生成する。
- LLM へのリクエストは OpenAI API または Claude API を設定で切り替えられるようにし、デフォルトでは `temperature=0.2`, `max_output_tokens=2048`, `response_format=markdown` を適用する。Mermaid コードは ` ```mermaid ` ブロックで囲むことを必須とする。
- 生成された Wiki は `/var/lib/dev-rag/wikis/<プロダクト名>/` ディレクトリ配下に Markdown ファイルとして出力する。
- 既存ファイルが存在する場合も常に上書きし、再現性を最優先とする。
- 生成された Wiki は再生成のたびに上書きされる前提であり、人手による修正が必要な場合は別の方法で管理する。

### 8.9 設定・環境管理機能

- システムは、.env形式の設定ファイルまたは環境変数から以下の設定を読み込める必要がある。
  - PostgreSQL 接続情報（ホスト、ポート、ユーザ、パスワード、DB 名）
  - OpenAI API キー
  - Embedding モデル名および次元数
  - Git クローン用ディレクトリパス（デフォルト：`/var/lib/dev-rag/repos`）
  - Git SSH鍵パス
  - Wiki 出力ディレクトリパス（デフォルト：`/var/lib/dev-rag/wikis`）
  - HTTP サーバポート（デフォルト：8080）
- .envファイルは godotenv ライブラリで読み込み、環境変数として利用する。
- CLI・HTTP サーバ・将来の MCP サーバともに、共通の設定ロジックを利用できるようにする。

### 8.10 REST API 機能

- システムは、HTTP サーバとして REST API を提供できなければならない。
- API のエンドポイントには、以下を含む（プロダクト=複数ソースの論理集合、ソース=個別情報源）。
  - `POST /api/v1/sources/index`: ソースのインデックス更新をトリガー（非同期、ボディで `sourceName` を指定）
  - `POST /api/v1/products/wiki`: プロダクト単位の Wiki 生成をトリガー（非同期、ボディで `productName` を指定）
  - `GET /api/v1/jobs/:jobID`: ジョブステータス確認
  - `GET /api/v1/products`: プロダクト一覧取得
  - `GET /api/v1/products/:productId`: プロダクト詳細取得
  - `GET /api/v1/products/:productId/sources`: プロダクトに紐づくソース一覧取得
  - `GET /api/v1/sources`: ソース一覧取得
  - `GET /api/v1/sources/:sourceId`: ソース詳細取得
  - `GET /api/v1/products/:productId/wiki`: プロダクトの最新 Wiki 情報取得
  - `GET /api/v1/products/:productId/wiki/files`: プロダクトの Wiki ファイル一覧取得
  - `GET /api/v1/products/:productId/wiki/files/:path`: プロダクトの Wiki ファイル取得（Markdown）
- JSON のキー名は Go 命名規則に準拠し、頭字語は大文字（`jobID`, `sourceURL` など）、それ以外はキャメルケース（`productName`, `sourceName`, `commitHash`, `generateWiki` 等）とする。
- API は認証トークン（Bearer Token）による認証をサポートする。
- 非同期処理のエンドポイント（index, wiki）は即座にジョブ ID を返却し、処理は Goルーチンでバックグラウンド実行する。

### 8.11 HTTP サーバ機能

- システムは、`dev-rag server start` コマンドで HTTP サーバを起動できなければならない。
- サーバはデフォルトでポート 8080 で起動する（設定ファイルで変更可能）。
- サーバは以下の機能を提供する。
  - REST API エンドポイント（8.9 参照）
  - 静的ファイル配信は行わない（wiki-viewer は別プロセスとして起動）
- インデックス処理や Wiki 生成などの長時間処理は、Goルーチンで非同期実行する。
- サーバはシグナル（SIGTERM, SIGINT）を受信したら、実行中のジョブを完了させてから正常終了する。

### 8.12 Wiki Viewer 機能

- システムは、生成された Wiki を閲覧するための Web アプリケーション（wiki-viewer）を提供する。
- wiki-viewer は Next.js（App Router）で実装され、独立したプロセスとして起動する。
- wiki-viewer は以下の機能を提供する。
  - ダッシュボード：リポジトリ一覧表示、各リポジトリの最終インデックス日時・Wiki 生成日時を表示
  - Wiki 表示：Markdown レンダリング、Mermaid 図の表示、サイドバーでのページナビゲーション
  - Wiki 再生成：ボタンクリックで REST API を呼び出し、バックグラウンドで Wiki を更新
  - ジョブステータス表示：ポーリングで処理状況を確認し、完了時に自動リロード
- wiki-viewer はバックエンド API（`http://localhost:8080`）と通信する。

### 8.13 ジョブ管理機能

- システムは、非同期処理のステータスをメモリ内で管理する。
- 各ジョブには一意な ID（UUID）が付与される。
- ジョブステータスには、以下の状態を含む。
  - `running`: 実行中
  - `completed`: 完了
  - `failed`: 失敗
- ジョブ情報には、ジョブ ID、リポジトリ名、ジョブ種別、ステータス、開始日時、終了日時、エラーメッセージ（失敗時）を含む。
- ジョブ情報はメモリ内に保持され、24 時間経過後に自動削除される。
- システム再起動時、メモリ内のジョブ情報は失われる（開発環境のため許容）。

---

## 9. 非機能要件

### 9.1 性能

- 中規模のリポジトリ（数万ファイル、数十万チャンク程度）に対して、
  ベクトル検索 1 回あたりの応答時間を数百ミリ秒程度に抑えることを目標とする。
- インデックス処理（初回フルインデックス）は CI 上で実行する前提とし、
  インデックス時間が長い場合は差分インデックスの活用により現実的な運用時間内に収まるようにする。
- 上記はベストエフォート指標であり、正式なベンチマークや SLA 測定は必須要件としない。

### 9.2 可用性・信頼性

- RAG 基盤はあくまで「開発者向けの補助システム」であり、本番業務システムよりは低い SLA でも許容されるが、
  開発時間帯に継続的に利用できる程度の可用性を目指す。
- Embedding は再生成可能なデータであるため、PostgreSQL のバックアップポリシーは本番 DB より緩く設定可能である。
  ただし、DB 完全消失時には再インデックスに時間がかかる点は考慮する。

### 9.3 セキュリティ

- Postgres サーバおよび本システムは、社内ネットワークまたは適切に閉じたネットワーク内で運用する。
- OpenAI API キーは環境変数や Secret 管理ツールを通じて安全に管理する。
- 対象リポジトリのコードやドキュメントは機密情報を含み得るため、
  外部ベクトルストア（OpenAI Vector Store 等）には送信しない。
- 想定利用者はローカル開発者に限定し、追加のアクセス制御や監査ログは実装しない。

### 9.4 拡張性

- データモデルは、複数の情報ソース（Git、Confluence、PDF、Redmine、Notion等）に対応できる汎用的な設計とする。
  - `sources` テーブルで情報ソースを抽象化
  - `source_snapshots` テーブルでソースのバージョン管理を抽象化
  - ソースタイプ固有の情報は metadata（JSONB）で柔軟に管理
- 初期フェーズでは Git リポジトリのみを実装するが、将来的に他のソースタイプを追加する際にスキーマ変更を最小限に抑える。
- 検索 API は、将来 MCP サーバ・RAG チャット API・別の内部ツールから再利用可能な形で提供する。

### 9.5 運用性

- インデックス処理は CLI として提供し、ローカル・CI のどちらからも同じコマンドで実行できるようにする。
- Postgres のバックアップ／リストアにより、RAG 基盤を別環境に移行可能とする。
- ログ出力・メトリクス出力は最低限行い、エラー時の原因調査が可能な状態を確保する。

---

## 10. 制約条件

- 開発言語は Go を使用する。
- ベクトルストアは PostgreSQL + pgvector 拡張に限定する。
- Embedding モデルは OpenAI Embeddings のみを利用対象とし、その他のベンダーは考慮しない。
- MCP サーバは将来実装とし、初期フェーズでは CLI と内部検索 API のみを提供する。

---

## 11. 将来拡張

本要件定義の範囲を超えるが、設計段階で考慮しておくべき将来拡張として、以下を想定する。

1. **RAG チャット API**
   - REST / gRPC などでチャット用 API を提供し、
     クライアントからの質問に対して RAG による回答を返す。

2. **MCP サーバ実装**
   - JSON-RPC over stdio で動作する MCP サーバを実装し、
     `search` や `get_document_count` などのツールを提供する。
   - Claude Desktop など MCP 対応クライアントから、社内 RAG ツールとして利用されることを想定する。

3. **対象ソースの拡大**
   - **Confluence**: Confluenceスペースのページを自動取得してインデックス化
   - **PDF**: PDFディレクトリを監視し、テキスト抽出してインデックス化
   - **Redmine**: チケットシステムの内容を取り込み、障害対応ナレッジとして活用
   - **Notion**: Notionデータベースのページを自動同期してインデックス化
   - **ローカルファイル**: 指定ディレクトリ配下のMarkdown/テキストファイルをインデックス化

   これらは既存の `sources` / `source_snapshots` スキーマで対応可能。

4. **自動ラベリング・分類**
   - Embedding を用いてドキュメントにタグを自動付与し、
     検索性を高める機能を追加する。

---
