# RAG検索精度向上システム 設計書

## 1. 概要

### 1.1 目的

本設計書は、RAGシステムにおける検索・取得精度を向上させるための包括的なアプローチを定義する。データ格納後の検索フェーズにおいて、ユーザーのクエリに対して最も適切なチャンクを高精度かつ高速に返却することを目標とする。

### 1.2 設計方針

- **段階的な精度向上**: 粗い検索から精緻な検索へと段階的に絞り込むマルチステージアプローチを採用
- **柔軟な拡張性**: モジュール単位で機能を追加・変更できる設計とする
- **データ品質との連携**: インジェストフェーズで付与されたメタデータを活用し、品質に基づく検索を実現
- **継続的な改善**: 評価指標とフィードバックループを組み込み、運用を通じた精度向上を可能にする

### 1.3 スコープ

本設計の対象範囲は以下の通り:

- ユーザークエリの理解と前処理
- 検索パイプラインの設計
- ランキングおよびリランキング手法
- パフォーマンス最適化
- 評価・モニタリング基盤

インジェストフェーズやUI/UX設計は本設計書の対象外とする。

---

## 2. システムアーキテクチャ

### 2.1 全体フロー

検索システムは以下の流れで動作する:

1. **クエリ前処理**: ユーザーの入力を解析し、検索に適した形式に変換
2. **マルチステージ検索**: 複数の段階で候補を絞り込み
3. **リランキング**: 多次元スコアリングにより最終的な順位を決定
4. **結果返却**: 上位チャンクをコンテキストとして返却
5. **フィードバック収集**: 検索結果の品質を記録し、継続的改善に活用

### 2.2 レイヤー構成

システムは以下のレイヤーで構成される:

- **クエリ理解レイヤー**: intent分類、クエリ再書き換え、シグナル拡張
- **検索実行レイヤー**: ベクトル検索、キーワード検索、メタデータフィルタリング
- **ランキングレイヤー**: スコアリング、リランキング、品質フィルタリング
- **最適化レイヤー**: キャッシング、インデックス最適化、パフォーマンス監視
- **評価レイヤー**: オフライン評価、オンライン評価、KPIモニタリング

---

## 3. クエリ理解と前処理

### 3.1 設計意図

ユーザーの入力クエリは曖昧性や表記ゆれを含むことが多い。検索精度を向上させるためには、クエリの意図を正確に理解し、検索に適した形式に変換する必要がある。

### 3.2 クエリ分類

**目的**: クエリのintentを判定し、検索戦略を切り替える

クエリは以下のようなカテゴリに分類される:

- コードリーディング: 特定の関数やクラスの実装を知りたい
- API仕様: エンドポイントやインターフェースの詳細を知りたい
- 設計議論: アーキテクチャや設計判断の背景を知りたい
- 運用手順: デプロイや障害対応などの手順を知りたい

**実装ガイドライン**:

- LLMベースの分類器またはルールベースの分類器を使用
- intent別に検索対象のファイルタイプや重み付けを調整
- 分類結果は検索パイプライン全体で参照可能にする

**Intent別検索戦略マッピング**:

以下の表は、各intentに対する推奨検索戦略を示す。実装時には外部設定ファイル（YAML、JSON、またはDBテーブル）として管理し、運用を通じて調整可能にする。

| Intent | 優先ファイルタイプ | structure_type フィルタ | ベクトル/キーワード重み | クエリ再書き換え | シグナル拡張 | 重要視するスコア要素 |
|--------|-------------------|------------------------|----------------------|-----------------|-------------|---------------------|
| コードリーディング | `.go`, `.py`, `.ts`, `.java` | `function`, `class`, `method` | ベクトル 0.7 / キーワード 0.3 | 有効 | 中程度 | ベクトル類似度、構造タイプ一致 |
| API仕様 | `.md`, `.yaml`, `.json`, API定義ファイル | `file`, `directory` | ベクトル 0.6 / キーワード 0.4 | 有効 | 高 | キーワード一致、パス関連性 |
| 設計議論 | `.md`, `docs/`, `design/`, コミットメッセージ | `file`, `directory` | ベクトル 0.8 / キーワード 0.2 | 有効 | 高 | 重要度スコア、新しさ |
| 運用手順 | `.md`, `README`, `RUNBOOK`, `docs/ops/` | `file`, `directory` | ベクトル 0.5 / キーワード 0.5 | 有効 | 中程度 | 新しさ、キーワード一致 |
| デフォルト（未分類） | すべて | フィルタなし | ベクトル 0.7 / キーワード 0.3 | 無効 | 低 | ベクトル類似度 |

**設定キー例（YAML形式）**:

```yaml
intent_strategies:
  code_reading:
    file_types: [".go", ".py", ".ts", ".java"]
    structure_types: ["function", "class", "method"]
    vector_weight: 0.7
    keyword_weight: 0.3
    enable_rewrite: true
    signal_expansion: "medium"  # low/medium/high
    scoring_weights:
      vector_similarity: 0.5
      keyword_match: 0.2
      structure_type_match: 0.15
      importance: 0.1
      freshness: 0.05

  api_spec:
    file_types: [".md", ".yaml", ".json", "openapi.yaml", "swagger.json"]
    structure_types: ["file", "directory"]
    vector_weight: 0.6
    keyword_weight: 0.4
    enable_rewrite: true
    signal_expansion: "high"
    scoring_weights:
      vector_similarity: 0.3
      keyword_match: 0.35
      path_relevance: 0.2
      importance: 0.1
      freshness: 0.05

  design_discussion:
    file_types: [".md"]
    path_patterns: ["docs/", "design/", "ADR/"]
    structure_types: ["file", "directory"]
    vector_weight: 0.8
    keyword_weight: 0.2
    enable_rewrite: true
    signal_expansion: "high"
    scoring_weights:
      vector_similarity: 0.4
      importance: 0.3
      freshness: 0.2
      keyword_match: 0.1

  operations:
    file_types: [".md"]
    path_patterns: ["README", "RUNBOOK", "docs/ops/", "docs/deploy/"]
    structure_types: ["file", "directory"]
    vector_weight: 0.5
    keyword_weight: 0.5
    enable_rewrite: true
    signal_expansion: "medium"
    scoring_weights:
      freshness: 0.3
      keyword_match: 0.3
      vector_similarity: 0.25
      path_relevance: 0.15
```

**注意事項**:

- 上記の重みは初期値であり、A/Bテストを通じて最適化する
- `signal_expansion`の具体的な適用度（low/medium/high）は、追加する同義語・関連語の数で制御（low: 1-2語、medium: 3-5語、high: 5-10語）
- リポジトリ特性に応じて、独自のintentカテゴリを追加可能

### 3.3 クエリ再書き換え

**目的**: 曖昧なクエリを標準化し、recall（再現率）を向上させる

ユーザーのクエリは、以下のような処理を経て検索に適した形式に変換される:

- Issue番号や略語を正式名称に展開
- 冗長な表現を簡潔化
- 技術用語の標準化

**実装ガイドライン**:

- LLMを用いたクエリ再書き換え機能を実装
- 原文と再書き換え版の両方で検索を行い、結果をマージ
- リポジトリ固有の用語辞書を構築し、精度を向上

### 3.4 シグナル拡張

**目的**: クエリに関連する情報を自動補完し、ヒット率を底上げする

以下の情報源から関連語を抽出し、クエリに追加する:

- リポジトリのREADME、タグ、トピック
- コミットメッセージやPR説明
- 同義語・略語の展開

**実装ガイドライン**:

- リポジトリメタデータをインデックス化し、高速に参照できるようにする
- シグナル拡張の適用度合いを調整可能にする（過度な拡張は精度低下を招く）
- ドメイン固有の辞書をメンテナンス可能な形で管理

---

## 4. マルチステージ検索パイプライン

### 4.1 設計意図

すべてのチャンクに対して高精度な検索を行うことは計算コストが高い。そのため、段階的に候補を絞り込むマルチステージアプローチを採用する。

### 4.2 検索パイプライン全体フロー

以下の表は、各段階の入出力、責務、次段階への受け渡し内容を示す。

| 段階 | 名称 | 入力 | 責務 | 出力（候補件数） | 付与スコア | 次段階へ渡すデータ |
|------|------|------|------|------------------|-----------|------------------|
| **Stage 0** | 前処理フィルタ | ユーザークエリ、intent | 強制除外フィルタ適用（`ingest_status="needs_fix"`、`secret_scan=detected`）| 検索対象チャンク全体（除外後） | なし | 検索可能チャンク集合、intent設定 |
| **Stage 1** | コース検索 | 検索可能チャンク、クエリEmbedding、intent設定 | 軽量ベクトル検索＋キーワード検索、メタデータフィルタ適用（`structure_type`, `language`, `file_type`） | 200件程度 | `coarse_vector_score`, `keyword_score` | チャンクID、スコア、メタデータ |
| **Stage 2** | ファイン検索 | Stage 1の200件 | Cross-Encoder リランキング、ハイブリッドスコア統合 | 20件程度 | `fine_vector_score`, `cross_encoder_score`, `hybrid_score` | チャンクID、統合スコア、メタデータ |
| **Stage 3** | 多次元リランキング | Stage 2の20件 | 品質フィルタ適用（`stale`, `source_quality`）、多次元スコアリング（ベクトル・キーワード・重要度・新しさ・パス関連性） | 10-15件 | `final_score`（多次元統合） | チャンクID、最終スコア、品質メタデータ |
| **Stage 4** | 文脈検証 | Stage 3の10-15件 | LLMによる十分性チェック | 十分 → 結果返却 / 不足 → Stage 0へ再帰（最大2回） | なし | 最終結果チャンク集合 or 拡張クエリ |

**重要な設計原則**:

1. **Stage 2とStage 3の責務分離**:
   - **Stage 2（ファイン検索）**: クエリとチャンクの意味的関連性を高精度に評価することに特化。Cross-EncoderやハイブリッドスコアはあくまでStage 1の粗選別結果を精緻化するための中間スコア。
   - **Stage 3（多次元リランキング）**: Stage 2の結果に対して、品質・新しさ・重要度などの多次元要素を加味し、**最終順位**を決定。Stage 2のスコアは`hybrid_score`として多次元スコアリングの一要素となる。

2. **スコア統合の具体例**:
   - Stage 3での最終スコア計算式:
     ```
     final_score =
       (stage2_hybrid_score × intent_weights.vector_similarity) +
       (keyword_match_score × intent_weights.keyword_match) +
       (importance_score × intent_weights.importance) +
       (freshness_score × intent_weights.freshness) +
       (path_relevance_score × intent_weights.path_relevance) +
       (quality_penalty_or_boost)
     ```
   - `stage2_hybrid_score`はStage 2で計算されたベクトル＋キーワードの統合スコア
   - `quality_penalty_or_boost`は`stale`フラグや`source_quality`に基づく加減算

3. **Stage間のデータ受け渡し**:
   - 各Stageは前段階のスコアをメタデータとして保持するが、最終的にはStage 3で計算される`final_score`のみが順位決定に使用される
   - デバッグ用に、各Stageのスコアはログとして保存

### 4.3 Stage 0: 前処理フィルタ

**目的**: 品質上の問題があるチャンクを検索対象から強制除外

この段階では、検索を実行する前に以下のチャンクを除外する:

- `ingest_status = "needs_fix"`: インジェスト時の検証で問題が検出されたチャンク
- `ingest_status = "excluded"`: 意図的に検索対象外とされたチャンク
- `secret_scan = "detected"`: シークレット情報が検出されたチャンク

**実装ガイドライン**:

- PostgreSQLのWHERE句で除外条件を適用（インデックスを活用して高速化）
- 除外されたチャンク数をメトリクスとして記録
- 除外理由は後続の分析に活用

### 4.4 Stage 1: コース検索

**目的**: 軽量な手法で候補を粗選別し、高速レスポンスを実現

この段階では、以下のいずれかまたは組み合わせにより、数百件の候補を取得する:

- 軽量なベクトル検索（低次元Embedding、近似最近傍探索）
- キーワードベースのフルテキスト検索
- メタデータによる絞り込み（言語、ファイルタイプ、タグ）

**実装ガイドライン**:

- PostgreSQLのpgvectorまたは専用ベクトルDBを使用
- 目標: 200ms以内のレスポンス
- 候補数は200件程度を目安とする

### 4.5 Stage 2: ファイン検索

**目的**: 高精度な手法で候補を絞り込み、精度とレイテンシのバランスを取る

第1段階の候補に対して、以下の手法で精緻な評価を行う:

- 高精度ベクトル検索（高次元Embedding、精密距離計算）
- Cross-Encoder型リランカー（クエリとチャンクのペアをスコアリング）
- ハイブリッドスコアリング（ベクトル + キーワード）

**実装ガイドライン**:

- リランキングモデルは別プロセスまたはサービスとして実装可能
- 目標: 500ms以内のレスポンス
- 候補数は20件程度に縮約

### 4.6 Stage 3: 多次元リランキング（詳細は第6章を参照）

**目的**: 複数の観点から最終的な順位を決定

Stage 2の結果に対して、以下を実施:

- 品質フィルタ適用（`stale`チャンク減点、`source_quality`によるブースト/ペナルティ）
- 多次元スコアリング（ベクトル類似度、キーワード一致、重要度、新しさ、パス関連性）
- intent別の重み適用

詳細は[第6章 リランキング](#6-リランキング)を参照。

### 4.7 Stage 4: 文脈検証

**目的**: 検索結果が回答生成に十分かを検証し、必要に応じて追加検索を実行

検索結果をLLMに渡し、以下を評価する:

- 回答生成に必要な情報が含まれているか
- 情報が不足している場合、どのような追加情報が必要か

**実装ガイドライン**:

- システムプロンプトで明示的に「十分性」を問う
- 不足時はクエリ拡張を行い、再検索を実行（再帰は最大2回程度に制限）
- 目標: 1000ms以内のレスポンス

---

## 5. ハイブリッド検索

### 5.1 設計意図

ベクトル検索は意味的類似性に強く、キーワード検索は正確な用語マッチに強い。両者を組み合わせることで、互いの弱点を補完する。

### 5.2 ベクトル検索とキーワード検索の統合

**アプローチ**:

- PostgreSQLのpgvector（ベクトル検索）とFull-Text Search（キーワード検索）を併用
- 各手法のスコアを正規化し、重み付けして統合
- 重み例: ベクトル 0.7、キーワード 0.3（intent別に調整可能）

**実装ガイドライン**:

- スコア正規化手法を統一（Min-Max正規化、Z-score正規化など）
- 重みパラメータを外部設定ファイルまたはDBで管理し、動的に調整可能にする
- A/Bテストにより最適な重みを探索

### 5.3 メタデータフィルタリング

**目的**: 構造化されたメタデータを活用し、検索精度を向上させる

以下のメタデータによる絞り込みを実装する:

- `structure_type`: function、class、method、file、directory
- `language`: Python、Go、Markdownなど
- `importance_score`: ファイルの重要度（中心性、更新頻度など）
- `tags`: 自動付与またはマニュアルで設定されたタグ
- `source_quality`: インジェストフェーズで評価された品質スコア
- `ingest_status`: 正常、要修正、除外などのステータス

**実装ガイドライン**:

- PostgreSQLのGINインデックスを活用し、高速なメタデータ検索を実現
- フィルタ条件はクエリintentに応じて動的に変更
- 低品質データ（`ingest_status="needs_fix"`）は検索結果から除外

---

## 6. リランキング

### 6.1 設計意図

検索段階で得られたスコアは単一次元であることが多い。リランキングでは、複数の観点からスコアを総合評価し、最終的な順位を決定する。

### 6.2 多次元スコアリング

**スコアリング要素**:

各チャンクは以下の要素でスコアリングされる:

- **ベクトル類似度** (重み 0.5): クエリとの意味的近さ
- **キーワード一致** (重み 0.2): 正確な用語マッチ
- **重要度スコア** (重み 0.15): ファイルの中心性や参照頻度
- **新しさ** (重み 0.1): 最終更新日時の新しさ
- **パス関連性** (重み 0.05): クエリに含まれるファイル名やディレクトリとの一致

**実装ガイドライン**:

- 各要素のスコアを0-1に正規化
- 重み付き加算により最終スコアを算出
- 重みはintent別に調整可能な設計とする

### 6.3 動的重み調整

**目的**: クエリintentに応じて、スコアリング重みを最適化

例:

- コードリーディングintent: ベクトル類似度と構造タイプを重視
- 運用手順intent: 新しさとキーワード一致を重視
- 設計議論intent: 重要度スコアとパス関連性を重視

**実装ガイドライン**:

- intent別の重みプリセットを用意
- A/Bテストにより最適な重みを継続的に探索
- 重み調整の履歴をログとして保存

---

## 7. 階層的検索

### 7.1 設計意図

チャンクは階層構造を持つ（ファイル > クラス > メソッド など）。マッチしたチャンクの前後関係や親子関係を提供することで、文脈理解を助ける。

### 7.2 親チャンク取得

**目的**: マッチしたチャンクの親チャンクを自動取得し、全体像を提供

例:

- メソッドチャンクがマッチした場合、そのクラス全体を取得
- クラスチャンクがマッチした場合、ファイル全体を取得

**実装ガイドライン**:

- `parent_chunk_id`を辿ることで親チャンクを取得
- 親チャンクはコンテキストとして追加（ランキング対象外）
- 取得する親の深さは設定可能にする（1階層 or ファイルルートまで）

### 7.3 子チャンク展開

**目的**: 親チャンクがマッチした場合、詳細情報として子チャンクを提供

例:

- ファイルチャンクがマッチした場合、含まれる関数やクラスのリストを取得
- クラスチャンクがマッチした場合、メソッド一覧を取得

**実装ガイドライン**:

- `parent_chunk_id`を逆引きして子チャンクを取得
- 子チャンクは折りたたみ表示などのUIで提供（全文展開は避ける）
- 子チャンクの取得数に上限を設ける（例: 最大10件）

---

## 8. 品質フィルタリング

### 8.1 設計意図

インジェストフェーズで評価された品質メタデータを活用し、低品質チャンクの影響を抑制する。

### 8.2 フィルタ適用順序と制御方式

品質・メタデータフィルタは、検索パイプラインの異なる段階で適用される。以下の表は、各フィルタの適用タイミングと制御方式を示す。

| フィルタ種別 | 適用Stage | 適用方法 | 制御パラメータ | 影響 |
|------------|----------|---------|--------------|------|
| **強制除外フィルタ** | Stage 0（前処理） | WHERE句による完全除外 | `exclude_needs_fix`, `exclude_secrets` (bool) | 検索対象から完全削除 |
| `ingest_status = "needs_fix"` | Stage 0 | WHERE句 | デフォルト: true（除外） | 検証失敗チャンクを除外 |
| `ingest_status = "excluded"` | Stage 0 | WHERE句 | デフォルト: true（除外） | 意図的に除外されたチャンクを除外 |
| `secret_scan = "detected"` | Stage 0 | WHERE句 | デフォルト: true（除外） | シークレット検出チャンクを除外 |
| **メタデータフィルタ** | Stage 1（コース検索） | WHERE句による絞り込み | intent設定に基づく動的フィルタ | 候補集合を絞り込み、検索速度向上 |
| `structure_type` | Stage 1 | WHERE句 | `filter_structure_types: [list]` | 例: `["function", "class"]` |
| `language` | Stage 1 | WHERE句 | `filter_languages: [list]` | 例: `["go", "python"]` |
| `file_type` | Stage 1 | WHERE句 | `filter_file_types: [list]` | 例: `[".md", ".go"]` |
| `path_patterns` | Stage 1 | WHERE句（LIKE/正規表現） | `filter_path_patterns: [list]` | 例: `["docs/", "README"]` |
| **品質スコアフィルタ** | Stage 3（多次元リランキング） | スコア減算・ブースト | `enable_stale_penalty`, `enable_quality_boost` (bool) | 最終スコアに影響 |
| `stale` フラグ | Stage 3 | スコア減算 | `stale_penalty_factor: 0.3`（元スコア × 0.7） | Staleチャンクのスコアを減点 |
| `source_quality` | Stage 3 | スコア加減算 | `quality_boost_factor: 0.2`（高品質）、`quality_penalty_factor: 0.3`（低品質） | 品質に応じてスコアを調整 |
| `validation_errors` | Stage 3 | スコア減算 | `validation_penalty: 0.1`（エラーあり） | Lint/Link失敗でスコア減点 |

**制御フラグの例（設定ファイル）**:

```yaml
filter_config:
  # Stage 0: 強制除外フィルタ
  exclude_needs_fix: true        # ingest_status="needs_fix"を除外
  exclude_secrets: true           # secret_scan="detected"を除外
  exclude_explicitly: true        # ingest_status="excluded"を除外

  # Stage 1: メタデータフィルタ（intentに応じて動的に変更）
  apply_structure_filter: true   # structure_typeフィルタを適用
  apply_language_filter: true    # languageフィルタを適用
  apply_file_type_filter: true   # file_typeフィルタを適用
  apply_path_filter: false       # デフォルトはパスフィルタ無効

  # Stage 3: 品質スコアフィルタ
  enable_stale_penalty: true     # staleチャンクにペナルティ適用
  stale_penalty_factor: 0.3      # 元スコア × (1 - 0.3) = 0.7
  enable_quality_boost: true     # source_qualityに基づくブースト/ペナルティ
  quality_boost_factor: 0.2      # 高品質（> 0.8）: スコア × 1.2
  quality_penalty_factor: 0.3    # 低品質（< 0.3）: スコア × 0.7
  enable_validation_penalty: true # 検証エラーにペナルティ適用
  validation_penalty: 0.1        # エラーごとにスコア × (1 - 0.1)
```

**重要な設計判断**:

1. **Stage 0での強制除外 vs Stage 3でのスコア減点**:
   - `ingest_status="needs_fix"`や`secret_scan="detected"`は**セキュリティ・品質上の重大問題**であるため、Stage 0で完全除外（検索対象外）
   - `stale`や低`source_quality`は**相対的な品質問題**であり、完全に無価値ではないため、Stage 3でスコア減点による順位調整

2. **メタデータフィルタのWHERE句適用理由**:
   - Stage 1でWHERE句を使うことで、ベクトル検索の対象件数を大幅に削減し、検索速度を向上
   - PostgreSQLのGINインデックスを活用することで、フィルタ自体のコストは低い

3. **品質スコアフィルタの遅延適用理由**:
   - Stage 1で`stale`や`source_quality`をフィルタすると、有用な情報を含むチャンクが完全に除外される可能性がある
   - Stage 3でスコア調整にとどめることで、古いが唯一の情報源であるチャンクも候補として残る

### 8.3 Staleチャンク除外

**目的**: 古くなったチャンクの順位を下げる

`last_modified`が一定期間以上前のチャンクは、`stale`フラグが付与される。検索時には以下の処理を行う:

- Staleチャンクのスコアを減算（例: 元スコア × 0.7）
- または、明示的にフィルタリングして除外

**実装ガイドライン**:

- `max_staleness_days`をリポジトリ別に設定可能にする
- Staleフラグの付与はバッチ処理で定期実行
- Staleチャンクの除外/減点は検索パラメータで制御可能

### 8.4 Source Quality によるランキング

**目的**: 高品質ソースを優先し、低品質ソースを抑制

`source_quality`スコア（0.0-1.0）をランキングに反映する:

- 高品質: README、主要コード、公式ドキュメント
- 低品質: 自動生成コード、テストスナップショット、ビルド成果物

**実装ガイドライン**:

- `source_quality`をリランキングの多次元スコアリングに組み込む
- 品質スコアの計算ロジックはインジェストフェーズと連携
- 低品質ソースを完全除外するオプションも提供

### 8.5 Validation 結果の活用

**目的**: インジェスト時の検証結果を検索に反映

以下の検証結果を活用する:

- Lint/Test 失敗: コードの品質が低い可能性
- Link Check 失敗: ドキュメントが古い可能性
- Secret Scan 検出: 除外必須

**実装ガイドライン**:

- `ingest_status="needs_fix"`のチャンクは検索結果から除外
- 検証結果の重大度に応じてスコアを減算
- 検証エラーの詳細を`quality_notes`に記録し、改善に活用

---

## 9. Embedding 最適化

### 9.1 設計意図

Embeddingの品質は検索精度に直結する。モデル選択、ベクトル次元、ファインチューニング戦略を適切に設計する。

### 9.2 マルチベクトル戦略

**アプローチ**:

単一のEmbeddingベクトルではなく、複数のベクトルを組み合わせることで精度を向上:

- **ColBERT風デュアルタワー**: トークン単位でエンコードし、MaxSim（最大類似度）で評価
- **属性別ベクトル**: 内容ベクトルとメタデータベクトルを分離して保存
- **負例サンプリング**: 関連しないチャンクを負例として学習し、モデルをファインチューニング

**実装ガイドライン**:

- 実装コストと精度向上のトレードオフを評価
- まずは単一ベクトルで基盤を構築し、段階的にマルチベクトルへ移行
- ベクトル保存領域の増加に注意（インデックスサイズ、検索速度への影響）

### 9.3 モデル選択

**選択肢**:

- **高精度重視**: `text-embedding-3-large` (3072次元)
- **コスト重視**: `text-embedding-3-small` (1536次元)
- **次元圧縮**: PCA、OPQによる次元削減

**実装ガイドライン**:

- 初期構築時はコストと精度のバランスを考慮し、`text-embedding-3-small`を推奨
- リポジトリ規模や予算に応じてモデルを選択
- 次元圧縮は慎重に評価（精度低下リスクあり）

### 9.4 Embedding 品質モニタリング

**目的**: Embeddingモデルの品質劣化やドリフトを検知

以下の指標を定期的に監視:

- コサイン類似度分布の週次保存
- モデル更新時のベクトル変化量
- 重要ファイルの定点観測（Embeddingが安定しているか）

**実装ガイドライン**:

- モニタリング結果をダッシュボードで可視化
- 異常検知時はアラートを発行
- モデル更新時はA/Bテストで影響を評価

---

## 10. 評価とフィードバックループ

### 10.1 設計意図

検索精度の継続的改善には、定量的な評価とフィードバックループが不可欠。オフライン評価とオンライン評価を組み合わせる。

### 10.2 オフライン評価

**目的**: 開発環境で検索精度を定量評価

以下の手法で評価:

- **代表質問セット**: リポジトリ特有のクエリと理想的なチャンクをアノテーション
- **評価指標**:
  - Precision@5: 上位5件の適合率
  - Recall@20: 上位20件の再現率
  - nDCG@10: 順位を考慮した評価
  - ACR (Average Cumulative Rank): 累積順位平均

**実装ガイドライン**:

- 評価セットはJSON形式で管理し、バージョン管理
- CI/CDパイプラインに組み込み、回帰テストを自動化
- パラメータ変更時の影響を定量的に把握

**評価セットの構築・保守プロセス**:

1. **初期構築（P0リリース時）**:
   - リポジトリごとに最低20件の代表質問を用意
   - 各質問に対して、理想的なチャンク（1-5件）を人手でアノテーション
   - アノテーションは2名以上でクロスチェック（一致率 > 80%を目標）

2. **継続的更新**:
   - 週次で実運用ログから「検索失敗」「低評価」クエリを抽出
   - 月次で評価セットに5-10件追加（合計50件を目標）
   - リポジトリの主要更新（大規模リファクタリング、主要機能追加）時に評価セットを見直し

3. **アノテーション責任者**:
   - リポジトリメンテナまたはドメインエキスパートが担当
   - アノテーション結果はGitで管理（例: `eval_sets/{repo_name}/queries.json`）

**目標KPI（P0/P1/P2での合格ライン）**:

| 指標 | P0目標 | P1目標 | P2目標 | 測定方法 |
|------|-------|-------|-------|---------|
| Precision@5 | ≥ 0.6 | ≥ 0.7 | ≥ 0.8 | 上位5件中の適合チャンク割合 |
| Recall@20 | ≥ 0.7 | ≥ 0.8 | ≥ 0.85 | 上位20件中に理想チャンクが含まれる割合 |
| nDCG@10 | ≥ 0.65 | ≥ 0.75 | ≥ 0.85 | 順位を考慮した総合評価 |
| ACR | ≤ 10 | ≤ 5 | ≤ 3 | 理想チャンクの平均順位（低いほど良い） |
| 評価セット件数 | ≥ 20 | ≥ 35 | ≥ 50 | リポジトリあたりの質問数 |

**CI回帰テストの合格条件**:

- 上記指標がすべて目標を満たすこと
- または、前回テストからの**劣化が5%以内**であること（例: Precision@5が0.70 → 0.665は許容）
- 劣化が5%を超える場合、CIは失敗とし、原因調査を必須とする

### 10.3 オンライン評価

**目的**: 実運用環境で検索品質を継続的に監視

以下のフィードバックを収集:

- **クエリメタログ**: intent、検索結果数、失敗理由
- **Implicit Feedback**: 追加質問の有無、再実行回数、クリック位置
- **Explicit Feedback**: 👍/👎ボタン、コメント

**実装ガイドライン**:

- ログデータを匿名化して保存
- A/Bテストにより、リランカーやハイブリッド重みの最適化を実施
- フィードバックを週次で分析し、改善ポイントを特定

**オンライン評価の目標KPI**:

| 指標 | P0目標 | P1目標 | P2目標 | 測定方法 |
|------|-------|-------|-------|---------|
| 検索成功率 | ≥ 80% | ≥ 85% | ≥ 90% | 0件結果以外の割合 |
| ユーザー満足度（👍率） | ≥ 60% | ≥ 70% | ≥ 80% | 👍 / (👍 + 👎) |
| 追加質問率 | ≤ 40% | ≤ 30% | ≤ 20% | 同一セッション内での再検索割合 |
| 平均レスポンスタイム（p95） | ≤ 2000ms | ≤ 1500ms | ≤ 1000ms | Stage 4完了までの時間 |
| キャッシュヒット率 | ≥ 20% | ≥ 30% | ≥ 40% | キャッシュから返却した割合 |

**A/Bテストの実施基準**:

- 新機能・パラメータ変更は必ず10%のトラフィックでA/Bテスト実施
- 最低100クエリ以上のサンプルサイズを確保
- 統計的有意差（p < 0.05）が確認された場合のみロールアウト
- 劣化が検出された場合は即座にロールバック

### 10.4 品質KPIモニタリング

**目的**: データ品質が検索精度に与える影響を可視化

以下のKPIを監視:

- `ingest_status`別ヒット率
- `source_quality`と回答満足度の相関
- `stale`チャンクの含有率

**実装ガイドライン**:

- ダッシュボードで可視化（Grafana、Metabaseなど）
- 異常値検知時はアラート
- KPI推移を週次レポートとして自動生成

**品質KPIの目標値とアラート閾値**:

| KPI | 目標値 | アラート閾値 | 測定頻度 |
|-----|--------|------------|---------|
| `ingest_status="ready"`の割合 | ≥ 95% | < 90% | 日次 |
| `stale`チャンクの含有率（検索結果内） | ≤ 10% | > 20% | 週次 |
| `source_quality`平均スコア（検索結果内） | ≥ 0.7 | < 0.5 | 週次 |
| `ingest_status="needs_fix"`のヒット率 | = 0%（除外されているはず） | > 0% | 日次 |
| 検証エラーあり（`validation_errors > 0`）の割合 | ≤ 5% | > 15% | 週次 |

**分析レポートの内容（週次自動生成）**:

1. **KPI推移グラフ**: 過去4週間の推移
2. **intent別ヒット率**: どのintentで品質問題が多いか
3. **低品質チャンクTop 10**: `source_quality`が低いが頻繁にヒットするチャンク
4. **Staleチャンク警告リスト**: 180日以上更新がないがヒット頻度の高いチャンク
5. **改善アクション提案**: LLMを活用した自動提案（優先度付き）

**アラート発行条件**:

- 上記KPIがアラート閾値を超えた場合、Slack/メールで通知
- 2週連続で閾値を超えた場合、重大アラートとして担当者にエスカレーション
- 月次で品質改善ミーティングを実施し、レポートをレビュー

---

## 11. パフォーマンス最適化

### 11.1 設計意図

高精度な検索を高速に提供するため、インデックス、キャッシング、クエリ最適化を実施。

### 11.2 インデックス最適化

**アプローチ**:

- **pgvector**: HNSW（高精度）またはIVFFlat（高速）を選択
- **パラメータチューニング**: ef_construction、m値の調整
- **メタデータ**: GINインデックスを活用した高速フィルタリング

**実装ガイドライン**:

- リポジトリ規模に応じてインデックスタイプを選択
- インデックス構築時間とクエリ速度のトレードオフを評価
- 定期的にVACUUM、ANALYZEを実行し、インデックスを最適化

### 11.3 キャッシング

**目的**: 頻出クエリのレスポンス時間を短縮

以下のキャッシング戦略を実装:

- **頻出クエリキャッシュ**: Redisに検索結果を保存
- **Embeddingメモ化**: 同一クエリのEmbedding計算を省略
- **検索結果の短期キャッシュ**: 数分間の有効期限を設定

**実装ガイドライン**:

- キャッシュキーにクエリとパラメータを含める
- キャッシュ有効期限をintent別に調整
- キャッシュヒット率をモニタリング

### 11.4 レスポンスタイム目標

各段階の目標レスポンスタイムを設定:

- 第1段階（コース検索）: 200ms以内
- 第2段階（ファインチューニング検索）: 500ms以内
- 第3段階（文脈検証）: 1000ms以内

**実装ガイドライン**:

- レスポンスタイムをログに記録し、p50/p95/p99を監視
- 目標を超過した場合はアラート
- ボトルネックをプロファイリングツールで特定

---

## 12. データ品質フィードバック

### 12.1 設計意図

検索結果の品質問題をインジェストフェーズにフィードバックし、データ品質を継続的に改善。

### 12.2 Quality Notes 収集

**目的**: 回答レビュー時の問題を記録し、改善に活用

以下の情報を収集:

- 不足している情報
- 古い情報
- 誤った情報

**実装ガイドライン**:

- チャンクレベルで`quality_notes`カラムに記録
- ユーザーインターフェースから簡単に問題報告できる仕組みを提供
- 収集した問題は優先度付けして管理

### 12.3 自動リメディエーション

**目的**: 品質問題を自動的に検知し、改善アクションを提案

以下のプロセスを実装:

- 週次で`quality_notes`を走査
- 再インデックスやドキュメント整備のバックログを自動作成
- 優先度付けと担当者アサインを提案

**実装ガイドライン**:

- LLMを活用して問題分類と優先度付けを自動化
- バックログ管理システム（GitHub Issues、Jiraなど）と連携
- 自動作成されたタスクは人間がレビュー

---

## 13. 実装優先度

### 13.1 P0（即時実装）

以下の機能は基本的な検索品質向上に不可欠であり、最優先で実装する:

- **Stage 0: 前処理フィルタ**: `ingest_status="needs_fix"`、シークレット検出チャンクの強制除外
- **Stage 1: コース検索**: ハイブリッド検索（ベクトル + キーワード）とメタデータフィルタリング
- **Intent分類**: 基本的な4カテゴリ（コードリーディング、API仕様、設計議論、運用手順）の判定
- **Intent別設定**: 外部YAMLファイルでの重み管理
- **オフライン評価**: 最低20件の評価セット構築、Precision@5 ≥ 0.6を目標

**P0完了条件**:
- オフライン評価でPrecision@5 ≥ 0.6、Recall@20 ≥ 0.7を達成
- レスポンスタイム（p95） ≤ 2000ms
- 評価セット20件以上を構築し、CI回帰テスト自動化

### 13.2 P1（1-2週間以内）

基本機能の稼働後、以下の機能で精度をさらに向上:

- **Stage 2: ファイン検索**: Cross-Encoderによるリランキング
- **Stage 3: 多次元リランキング**: 品質フィルタ適用、intent別重み調整
- **クエリ再書き換え**: LLMによる標準化、原文との両方で検索
- **階層的検索**: 親子チャンクの自動取得
- **オンライン評価**: クエリログ、Implicit/Explicit Feedback収集開始

**P1完了条件**:
- オフライン評価でPrecision@5 ≥ 0.7、nDCG@10 ≥ 0.75を達成
- オンライン評価で検索成功率 ≥ 85%、ユーザー満足度 ≥ 70%
- 評価セット35件以上に拡充
- ダッシュボードでKPI可視化

### 13.3 P2（3-4週間以内）

システムの成熟度を高めるための高度な機能:

- **Stage 4: 文脈検証**: LLMによる十分性チェックと再検索
- **シグナル拡張**: リポジトリメタデータ、コミットメッセージからの関連語抽出
- **マルチベクトル戦略**: ColBERT風のトークンレベルEmbedding（実験的）
- **Embedding品質モニタリング**: ドリフト検知と定点観測
- **A/Bテスト環境**: パラメータ最適化のための実験基盤

**P2完了条件**:
- オフライン評価でPrecision@5 ≥ 0.8、nDCG@10 ≥ 0.85を達成
- オンライン評価で検索成功率 ≥ 90%、ユーザー満足度 ≥ 80%
- 評価セット50件以上に拡充
- A/Bテストで少なくとも3つのパラメータ最適化を実施

### 13.4 P3（継続的改善）

運用を通じて継続的に改善する仕組み:

- **自動リメディエーション**: 品質問題の自動検知と改善提案、バックログ自動作成
- **品質KPIモニタリング**: 週次レポート自動生成、アラート発行
- **評価セットの継続的拡充**: 月次で5-10件追加、ドメインエキスパートによるレビュー
- **Intent辞書の拡充**: リポジトリ固有の用語、同義語の追加
- **Embeddingモデルの定期更新**: 新モデルへの移行評価、A/Bテスト

**P3運用基準**:
- 週次でKPIレポートをレビュー、改善アクションを決定
- 月次で品質改善ミーティングを実施
- 四半期でEmbeddingモデルや主要パラメータの見直し
- KPIアラートが2週連続で発火した場合、緊急対応チームを編成

---

## 14. 技術選定ガイドライン

### 14.1 ベクトルDB

- PostgreSQL + pgvector: 既存DBと統合しやすく、管理コストが低い
- 専用ベクトルDB（Qdrant、Weaviate、Pineconeなど）: 大規模データや高速検索が必要な場合に検討

### 14.2 リランカー

- Cross-Encoder（sentence-transformers、OpenAI Rerank APIなど）: 高精度だが計算コスト高
- 軽量スコアリング（TF-IDF、BM25など）: 高速だが精度は劣る

### 14.3 LLM

- クエリ再書き換え、文脈検証、自動リメディエーションにはLLMを活用
- コスト抑制のため、軽量タスクには小型モデル（GPT-4o-mini、Claude Sonnet）を使用

### 14.4 キャッシング

- Redis: 高速な検索結果キャッシュに最適
- CDN: 静的なクエリ結果の配信に活用

---

## 15. 運用とモニタリング

### 15.1 ログ設計

以下のログを記録:

- クエリログ: クエリ文字列、intent、検索結果数、レスポンスタイム
- スコアログ: 各チャンクのスコア詳細（デバッグ用）
- フィードバックログ: ユーザーの評価、問題報告

### 15.2 アラート設計

以下の条件でアラートを発行:

- レスポンスタイムが目標を継続的に超過
- 検索結果数が異常に少ない（0件が続く）
- Embedding品質の異常検知

### 15.3 ダッシュボード

以下の指標をリアルタイム監視:

- クエリ数、成功率、失敗率
- レスポンスタイム分布（p50、p95、p99）
- キャッシュヒット率
- 品質KPI（stale率、source_quality分布）

---

## 16. まとめ

本設計書は、RAG検索精度向上のための包括的なアプローチを提示した。実装においては、以下の点に留意すること:

- **段階的実装**: P0から順に実装し、各段階で評価を実施
- **柔軟性の確保**: パラメータや重みは外部設定化し、運用を通じて最適化
- **データ品質との連携**: インジェストフェーズで付与されたメタデータを最大限活用
- **継続的改善**: 評価とフィードバックループを組み込み、運用を通じて精度を向上

実装者は本設計書を指針としつつ、リポジトリの特性やユーザーニーズに応じて柔軟にカスタマイズすること。
