# RAGインジェストシステム設計書

## 1. 目的と適用範囲

本設計書は、dev-ragシステムにおけるソースコードおよびドキュメントのインデックス化プロセス(インジェスト)を定義する。精度の高い検索結果を得るため、チャンキング、メタデータ付与、Embedding生成、品質管理の各フェーズにおける設計原則と要件を示す。

### 1.1 設計目標

- **高精度な検索**: 構文・意味的に完結したチャンクを生成し、文脈を保持した検索を実現する
- **トレーサビリティ**: すべてのチャンクがGitコミット・スナップショットに紐付き、データの出所を追跡可能にする
- **継続的品質改善**: フィードバックを収集し、インデックス品質を定量的に評価・改善する仕組みを提供する
- **拡張性**: 新しい言語・ファイル形式への対応が容易な設計とする

### 1.2 適用範囲

本設計は以下のフェーズに適用される:

1. リポジトリからのファイル取得
2. チャンキング処理
3. メタデータ抽出・付与
4. Embeddingコンテキスト構築
5. ベクトルストアへの登録
6. 品質評価とフィードバックループ

---

## 2. システムアーキテクチャ概要

### 2.1 処理フロー

```
[Gitリポジトリ] → [チャンキング] → [メタデータ抽出] → [コンテキスト構築]
                                                              ↓
[品質フィードバック] ← [ベクトルストア登録] ← [Embedding生成]
```

### 2.2 主要コンポーネント

- **チャンカー**: ファイルを構文・意味的に適切な単位に分割する
- **メタデータエクストラクタ**: 構造情報、依存関係、品質メトリクス、バージョン情報を抽出する
- **コンテキストビルダー**: チャンクに文脈情報を付与してEmbedding用テキストを構築する
- **カバレッジアナライザー**: リポジトリのドメイン分類とインデックス網羅性を評価する
- **品質モニター**: インデックス品質を定量評価し、改善アクションを生成する

### 2.3 データモデル概要

チャンクは以下の情報を保持する:

- **ID**: 一意識別子(例: `{repo_id}/{file_path}#{line_range}`)
- **階層関係**: 親チャンクID、子チャンクIDリスト
- **コンテンツ**: 元テキスト、Embedding用拡張テキスト
- **メタデータ**: 構造情報、依存関係、品質メトリクス、バージョン情報、重要度スコア
- **起源情報**: `source_snapshot_id`、`git_commit_hash`

---

## 3. チャンキング戦略

### 3.1 設計原則

チャンク生成において以下の原則を遵守すること:

1. **構文的完結性**: コードブロックや文章が途中で切断されないこと
2. **意味的一貫性**: 関連する情報が同一チャンクに含まれること
3. **トークンサイズ制約**: 100〜1600トークンの範囲内に収めること
4. **検索最適化**: 検索クエリで期待される粒度とマッチすること

### 3.2 階層的チャンキング

リポジトリの情報を以下の3階層に分割し、親子関係を保持する:

#### レベル1: ファイル全体のサマリー(親チャンク)
- ファイル全体の役割・主要な構成要素・依存関係を要約したテキストを生成する
- LLMを使用して自動生成する(プロンプト仕様は後述)
- サマリーは400トークン以内に収める
- 実装者は要約品質を評価し、必要に応じてプロンプトを調整すること

#### レベル2: 関数/クラス単位(子チャンク)
- 1つの関数、クラス、メソッドを1チャンクとする
- ドキュメントコメントは対応するコード要素と同一チャンクに含める
- 実装者は言語ごとの境界判定ロジックを適切に実装すること

#### レベル3: ロジック単位(孫チャンク)
- 大きな関数を論理的な部分(初期化、ループ処理、エラーハンドリング等)に分割する
- 孫チャンクは親となる関数チャンクへの参照を保持する
- 実装者は循環的複雑度やコードブロックの深さを判断基準として利用してもよい

#### 親子関係の保持
- 各チャンクは `parent_chunk_id` フィールドで親を参照する
- 親チャンクは `child_chunk_ids` リストで子を参照する
- この双方向リンクにより、検索時に親・子チャンクを文脈として利用可能にする

### 3.3 AST解析によるソースコードチャンキング

ソースコードは構文解析ツールを使用してチャンクを生成すること:

#### 解析ツールの選定
実装者は対象言語に応じて以下のいずれかまたは類似ツールを使用する:
- Go: `go/ast`、`go/parser`
- TypeScript/JavaScript: tree-sitter、`@babel/parser`
- Python: `ast`モジュール、tree-sitter
- その他言語: tree-sitterまたは言語固有のパーサー

#### チャンク生成ルール
- 関数・メソッド・クラスの境界を識別し、構文木のノード単位で分割する
- ドキュメントコメント(GoDocやJSDocなど)はコードノードと統合する
- インポート文、型定義、グローバル変数などはファイルレベルのコンテキストとして保持する
- 構文エラーが発生する不完全なチャンクは生成しない

#### 依存関係の抽出
- インポート文から外部依存を抽出する
- 関数呼び出しから内部依存を抽出する
- 抽出した依存情報は後述のメタデータとして保存する

### 3.4 意味的チャンキング(Markdown/テキスト)

Markdownやドキュメントファイルは意味的境界で分割する:

#### 見出し構造の利用
- H1-H6の見出しレベルから階層構造を構築する
- H1セクションが親チャンク、H2以下が子チャンクとなるように階層を設定する
- 実装者は見出しの深さに応じて適切な階層レベルを選択してもよい

#### 構造要素の保全
以下の要素は分割しないこと:
- コードブロック(```で囲まれた領域)
- テーブル(Markdown table)
- リスト項目のグループ

#### セマンティック境界の判定
- 段落の区切り(空行)を主要な分割ポイントとする
- 実装者はトークン数制約との兼ね合いで段落をマージしてもよい
- 意味が不完全になる分割は避ける(例: 「以下の理由による:」の直後で分割しない)

### 3.5 チャンク品質検証

生成されたチャンクは以下の基準で検証し、不適格なチャンクを除外または再分割すること:

#### トークンサイズ
- 最小: 100トークン(短すぎる断片を避ける)
- 最大: 1600トークン(Embeddingモデルの入力制限に配慮)
- 実装者はtiktokenの`cl100k_base`トークナイザーで測定する
- サイズ超過時は再分割ロジックを実行する

#### 構文完全性
- ソースコードチャンクは構文エラーがないことを確認する
- 実装者は言語パーサーでの再パースや静的解析ツールでの検証を推奨する

#### 意味的完結性
- 不完全な文(主語や述語の欠落)がチャンクの末尾に残らないこと
- 実装者は自然言語処理ツール(文区切り検出)を利用してもよい

#### コメント比率の異常検出
- コードチャンクでコメント行が95%以上を占める場合は低品質と判定する
- 実装者は閾値を調整してもよいが、極端なケースは除外すること

---

## 4. メタデータ抽出・付与

### 4.1 メタデータの目的

メタデータはチャンクの検索精度向上・フィルタリング・ランキング調整に使用される。抽出精度が低いメタデータは欠損として扱い、無理に補完しないこと。

### 4.2 構造情報

#### 基本フィールド
- `type`: チャンクの種別を示す(例: `function`, `class`, `method`, `import`, `interface`, `struct`, `documentation`)
- `name`: 関数名、クラス名、見出しテキスト
- `parent`: 所属する親構造体、パッケージ、モジュール名
- `signature`: 関数シグネチャ(引数リスト、戻り値型)
- `doc_comment`: ドキュメンテーションコメント(GoDoc、JSDocなど)

#### 抽出方法
実装者はAST解析により構造情報を取得する。言語によって利用可能な情報が異なるため、取得できない項目は空値またはnullとする。

### 4.3 依存関係

#### インポート情報
- `imports`: インポートされているパッケージ・モジュール・ライブラリのリスト
- 標準ライブラリと外部依存を区別してもよい

#### 呼び出し関係
- `calls`: チャンク内で呼び出されている関数・メソッドのリスト
- 実装者はAST解析やシンボル解決ツールで抽出する
- 完全な呼び出しグラフは必須ではなく、主要な呼び出し先の記録で十分とする

### 4.4 コード品質メトリクス

以下のメトリクスを計測する:

- `cyclomatic_complexity`: 循環的複雑度(McCabeメトリクス)
  - 実装者は言語ごとの静的解析ツール(golangci-lint、ESLintプラグインなど)を利用してもよい
- `lines_of_code`: コード行数(コメント・空行を除外)
- `comment_ratio`: コメント行の割合(0.0〜1.0)

これらのメトリクスは後述の重要度スコア計算や品質評価に利用される。

### 4.5 バージョン情報

#### トレーサビリティ用フィールド
- `commit_hash`: Gitコミットハッシュ(フルハッシュを記録)
- `author`: 最終更新者のGit author情報
- `updated_at`: ファイルの最終更新日時(ISO 8601形式)
- `file_version`: システム内でのファイルバージョン識別子(オプション)

#### データ起源の保証
- すべてのチャンクに `source_snapshot_id` を付与し、どのスナップショット取得プロセスで作成されたかを記録する
- Provenance graphを構築可能にするため、チャンク生成時刻・バッチIDも保持してもよい

### 4.6 重要度スコア

以下の要素を組み合わせて重要度スコアを計算する:

#### 参照回数
- `reference_count`: 他のコードから参照される回数
- 実装者は依存関係解析ツールやシンボルインデックスを利用する

#### 中心性スコア
- `centrality_score`: 依存グラフ上での中心性(PageRankやBetweenness Centrality)
- 実装者はグラフ解析ライブラリを使用して計算する
- 計算コストが高い場合は簡易的な指標(入次数・出次数の合計など)で代替してもよい

#### 編集頻度
- `edit_frequency`: 過去N日間の変更回数
- Gitログから抽出する
- 頻繁に更新されるファイルは重要度が高いと見なす

#### スコアの正規化
実装者は各要素を0.0〜1.0に正規化し、重み付け平均で総合スコアを算出する。重みはシステム運用中に調整可能とすること。

---

## 5. Embeddingコンテキスト構築

### 5.1 コンテキスト拡張の目的

チャンク単体では文脈が不足し、検索精度が低下する場合がある。Embedding生成前にチャンク本体にメタ情報を前置することで、Embeddingに文脈情報を埋め込む。

### 5.2 拡張形式

以下の形式でコンテキストを構築する:

```
File: {file_path}
Package: {package_name}
Function: {function_name}
Parent: {parent_structure}

{チャンク本体}
```

#### フィールド選定
実装者は以下のルールでフィールドを選択する:
- 利用可能なメタデータのみを記載し、不明な項目は省略する
- ファイルパスは常に記載する
- コードの場合はPackage/Function/Parentを優先的に記載する
- ドキュメントの場合はFile/Section/Parentを記載する

### 5.3 サマリー追加(オプション)

高精度化が必要な場合、LLMによる要約をチャンク冒頭に追加してもよい:

```
Summary: {要約文(80トークン以内)}

{コンテキスト情報}

{チャンク本体}
```

#### 要約生成の方針
- 要約はチャンク本体を簡潔に説明する1〜2文とする
- 生成にはLLMを使用し、プロンプト仕様は後述する
- コスト・レイテンシを考慮し、重要度スコアが閾値を超えるチャンクのみ対象としてもよい

### 5.4 トークン制限への対応

拡張コンテキストを含めた総トークン数がEmbeddingモデルの入力上限を超える場合:
- チャンク本体を優先し、コンテキスト情報を削減する
- サマリーがある場合はサマリーのみを残してもよい
- 実装者は各Embeddingモデルの入力上限を確認し、適切にトリミングすること

---

## 6. カバレッジマップの構築

### 6.1 ドメイン分類

リポジトリ内のファイル・ディレクトリを以下の5つのドメインに分類する:

- **code**: アプリケーションコード、ライブラリコード
- **architecture**: 設計文書、ADR、アーキテクチャ図
- **ops**: CI/CD設定、監視設定、運用Runbook
- **tests**: テストコード、テストデータ
- **infra**: インフラ定義(Terraform、Kubernetes YAML、Helm Chartなど)

#### 分類方法
実装者は以下のアプローチを組み合わせて使用する:
1. ルールベース: パス・ファイル名パターンでの分類(例: `*_test.go` → tests)
2. LLM自動分類: ファイル内容のサンプルをLLMに渡して判定(プロンプト仕様は後述)

### 6.2 カバレッジの可視化

各ドメインについて以下の指標を集計し、可視化する:

- インデックス済みチャンク数
- 総ファイル数に対するカバレッジ率
- ドメイン別の平均品質スコア
- 未インデックスの重要ファイル(README、主要ADRなど)のリスト

### 6.3 アラート機能

以下の条件を満たす場合にアラートを発行する:
- 重要README(リポジトリルート、各主要ディレクトリ)が未インデックス
- ADRドキュメントが10件以上あるのに5件未満しかインデックス化されていない
- テストコードのカバレッジ率が20%未満

実装者はプロジェクトの特性に応じて閾値を調整してもよい。

---

## 7. データ起源トレーサビリティ

### 7.1 トレーサビリティの要求

RAGシステムの回答がどのソースに基づいているかを追跡可能にするため、すべてのチャンクに以下を埋め込む:

- `source_snapshot_id`: スナップショット取得バッチのID
- `git_commit_hash`: Gitコミットハッシュ
- `indexed_at`: インデックス作成日時

### 7.2 Provenance Graphの構築

検索結果に使用されたチャンクから、以下のような履歴を遡れるようにする:

```
回答 → チャンクA, チャンクB
チャンクA → README.md v12 (commit abc123)
チャンクB → ADR-003 v3 (commit def456)
```

実装者はチャンクIDとバージョン情報のマッピングをデータベースまたはグラフ構造で保持する。

### 7.3 履歴管理

同一ファイルの異なるバージョンのチャンクを区別するため:
- チャンクIDにバージョン情報を含める(例: `{file_path}#{line_range}@{commit_hash}`)
- 古いバージョンのチャンクは削除せず、`is_latest`フラグで管理する
- 実装者は検索時に最新バージョンを優先するランキング調整を行う

---

## 8. 品質フィードバックループ

### 8.1 フィードバック収集

RAG回答のレビュー時に、以下の情報を `quality_notes` として記録する:

- `note_id`: 一意識別子
- `severity`: 深刻度(critical / high / medium / low)
- `note_text`: 問題の内容(情報不足、古い情報、誤った情報など)
- `linked_files`: 関連するファイルパス
- `linked_chunks`: 関連するチャンクID
- `reviewer`: レビュー者
- `created_at`: 記録日時

### 8.2 週次レビュー

週次で `quality_notes` を分析し、以下のアクションを自動生成する:

- **reindex**: 古いバージョンが参照されている場合、最新コミットで再インデックス
- **doc_fix**: ドキュメント不足が指摘された場合、該当ファイルの改善タスク作成
- **test_update**: テストコードの情報が不足している場合、テストカバレッジ向上タスク作成
- **investigate**: 原因不明の品質問題の調査タスク作成

#### 自動生成ルール
実装者はLLMを使用してquality_notesからアクションを生成する(プロンプト仕様は後述)。生成されたアクションは優先度付けされ、チームのバックログに登録される。

### 8.3 品質メトリクスの定量評価

以下の指標を定期的に計測し、改善状況を追跡する:

- `quality_notes`の件数推移
- severityレベル別の内訳
- 解消されたnotesの数
- インデックスの鮮度(最新コミットとの差分日数)

実装者はこれらの指標をダッシュボードやレポートで可視化する。

---

## 9. LLMプロンプト仕様

### 9.1 運用ガイドライン

#### トークンカウント
- すべてのプロンプトで`tiktoken`の`cl100k_base`トークナイザーを使用する
- 入力・出力の合計トークン数を監視し、コスト管理に利用する

#### 温度設定
以下の温度パラメータを推奨値とする:
- ファイルサマリー生成: 0.3(安定性重視、ある程度の表現の幅)
- チャンク要約生成: 0.2(より決定論的)
- ドメイン分類: 0.0(完全に決定論的)
- アクション生成: 0.5(創造性と安定性のバランス)

実装者はシステム運用中に温度を調整してもよいが、初期値は上記を使用すること。

#### エラーハンドリング
- LLMが仕様外のJSON形式を返した場合、1回までリトライする
- 2回目も失敗した場合は `{"error":"parse_failed","prompt_section":"9.x"}` を返す
- 実装者は失敗したプロンプト・レスポンスをログに記録し、後で分析可能にする

#### レート・コスト管理
- 各プロンプトの平均トークン数:
  - ファイルサマリー: 1000トークン
  - チャンク要約: 350トークン
  - ドメイン分類: 450トークン
  - アクション生成: 800トークン
- 1分あたり最大10リクエストまで並列化し、超過分はキューイングする
- 実装者は使用するLLMプロバイダーのレート制限に応じて調整する

#### バージョン管理
- 各プロンプトのレスポンスに `prompt_version` フィールドを含める(初期値: "1.1")
- プロンプトを更新した場合はバージョンを上げ、パイプライン側で互換性をチェックする

### 9.2 ファイルサマリー生成プロンプト

#### 目的
ファイル全体を要約し、階層的チャンキングのレベル1(親チャンク)として使用する。

#### 入力パラメータ
- `file_path`: ファイルパス
- `file_language`: プログラミング言語またはファイル形式
- `file_content`: ファイルの全文

#### 制約条件
- Markdown形式で400トークン以内に収める
- 重要な関数・クラス・セクション、依存関係、副作用を網羅する
- 重要度の高い項目から降順に記述する
- 推測を避け、未確定情報は記載しない
- 3行以上のコードブロックは禁止(必要なら1〜2行をインラインコードで引用)

#### 出力形式
JSON形式で以下のフィールドを含む:
- `prompt_version`: プロンプトバージョン(例: "1.1")
- `summary`: 要約項目のリスト(3〜6項目、重要度降順)
- `risks`: リスクや注意点(0〜2項目)
- `metadata`:
  - `primary_topics`: 主要トピック(例: ["indexing", "configuration"])
  - `key_symbols`: 主要なシンボル(例: ["IndexSource", "Indexer"])

#### 出力例
```json
{
  "prompt_version": "1.1",
  "summary": [
    "HTTPサーバ起動処理とインデクサ初期化の流れを記述",
    "IndexSource関数がチャンク生成→埋め込み計算→ベクターストア登録を連鎖実行",
    "設定値はenvとconfigファイルをマージして解決"
  ],
  "risks": [
    "embedサービスへの同期呼び出しでレイテンシが高い"
  ],
  "metadata": {
    "primary_topics": ["indexing", "configuration"],
    "key_symbols": ["IndexSource", "Indexer"]
  }
}
```

### 9.3 チャンク要約生成プロンプト

#### 目的
個別チャンクを80トークン以内で要約し、Embedding前置文として使用する。

#### 入力パラメータ
- `chunk_id`: チャンクID(ログ相関用)
- `parent_context`: 親チャンクのサマリー(存在しない場合はnull)
- `chunk_content`: チャンク本文

#### 制約条件
- 1〜2文の陳述で完結し、命令形は禁止
- `parent_context`がnullの場合、ファイル全体の冒頭説明を参照文脈とし、親文脈不在であることを明示する
- 親文脈と矛盾させない
- 情報不足は「未定義」と明示
- 数値・定数は原文に存在する値のみ使用
- コード識別子は最大3個まで

#### 出力形式
JSON形式で以下のフィールドを含む:
- `prompt_version`: プロンプトバージョン
- `chunk_id`: 入力されたチャンクID
- `summary_sentence`: 要約文
- `focus_entities`: 重要なエンティティ(最大3件)
- `confidence`: 信頼度(0.2〜0.85)

#### 信頼度の目安
- 明確な入出力や副作用が特定できる: 0.75
- 記述が抽象的/情報不足: 0.55
- 親文脈と矛盾する可能性: 0.35以下

#### 出力例
```json
{
  "prompt_version": "1.1",
  "chunk_id": "src/indexer/indexer.go#L10-L68",
  "summary_sentence": "IndexSourceは受け取ったDocumentをバッチ分割し、EmbedClientでベクトル化後にVectorStoreへ一括登録する。",
  "focus_entities": ["IndexSource", "EmbedClient", "VectorStore"],
  "confidence": 0.75
}
```

### 9.4 ドメイン自動分類プロンプト

#### 目的
ファイル・ディレクトリをcode, architecture, ops, tests, infraのいずれかに分類する。

#### 入力パラメータ
- `node_path`: ファイル/ディレクトリパス
- `node_type`: `file` または `dir`
- `detected_language`: 検出された言語
- `stats`: `loc`(行数)、`last_modified`(最終更新日)、`owners`(所有者)
- `sample_lines`: ファイルのサンプル(最大50行: 先頭25行 + 末尾25行)
- `directory_hints`: ルールベース推定結果(例: `{"pattern":"*_test.go","suggested_domain":"tests"}`)

#### 制約条件
- 常に1ドメインのみ返却
- 情報不足時は"code"にフォールバック
- 判定理由は2文以内で行番号引用(例: `L12`)
- 追加ヒント:
  - tests: `*_test.*`, `*.spec.*`, `/tests/`配下
  - architecture: `docs/adr/`, `docs/design/`, `docs/decisions/`
  - ops: `.github/workflows/`, `ci/`, `monitoring/`
  - infra: `infra/`, `terraform/`, `k8s/`, `helm/`
- `directory_hints`がある場合は理由に参照を含める
- 不足情報は明示した上で合理的推論を行い、`confidence`を下げる

#### 出力形式
JSON形式で以下のフィールドを含む:
- `prompt_version`: プロンプトバージョン
- `domain`: 分類ドメイン
- `rationale`: 判定理由
- `confidence`: 信頼度(0.2〜0.9)

#### 出力例
```json
{
  "prompt_version": "1.1",
  "domain": "architecture",
  "rationale": "ADR-003が設計判断と背景を記載しており実装コードは含まれない (L5-L48)。",
  "confidence": 0.81
}
```

### 9.5 quality_notesからのアクション自動生成プロンプト

#### 目的
品質フィードバックを分析し、優先度付きバックログを生成する。

#### 入力パラメータ
- `week_range`: 対象週の期間
- `quality_notes`: notesのリスト(各noteは`note_id`, `severity`, `note_text`, `linked_files[]`, `reviewer`を含む)
- `recent_changes`: 最新コミット情報(`hash`, `files_changed[]`, `merged_at`)
- `codeowners_lookup`: ファイルパスからCODEOWNERSへのマッピング

#### 制約条件
- 各アクションに`action_type`を必ず付与: `reindex`, `doc_fix`, `test_update`, `investigate`
- `owner_hint`は`codeowners_lookup`を最優先、次に`reviewer`、なければ"unassigned"
- `priority`は`severity`から算出: `critical→P1`, `high→P2`, `medium/low→P3`
- `acceptance_criteria`は機械検証可能な条件を記述
- 1週間あたり最大5件(チームキャパシティの上限)
- `severity`降順でソート、超過分は`status:"noop"`
- `recent_changes`により解消済みなら`status:"noop"`とし、どのコミットで対処済みかを記述
- JSON配列のみを返し、前後に文章を付けない

#### 出力形式
JSON配列。各要素は以下のフィールドを含む:
- `prompt_version`: プロンプトバージョン
- `priority`: P1 / P2 / P3
- `action_type`: reindex / doc_fix / test_update / investigate
- `title`: アクションタイトル
- `description`: 詳細説明
- `linked_files`: 関連ファイルリスト
- `owner_hint`: 担当者ヒント
- `acceptance_criteria`: 受入基準
- `status`: open / noop

#### 出力例
```json
[
  {
    "prompt_version": "1.1",
    "priority": "P1",
    "action_type": "reindex",
    "title": "ADR-005とREADME.enの再インデックス",
    "description": "quality_notes #12 (severity:critical) で旧バージョン参照が指摘。commit 9f2d3b4 以降を再投入する。",
    "linked_files": ["docs/adr/ADR-005.md", "README.en.md"],
    "owner_hint": "architecture-team",
    "acceptance_criteria": "VectorStoreにcommit 9f2d3b4のチャンクが存在することを nightly チェックで確認する。",
    "status": "open"
  },
  {
    "prompt_version": "1.1",
    "priority": "P2",
    "action_type": "doc_fix",
    "title": "IndexSourceパラメータ説明の追記",
    "description": "quality_notes #42 (severity:high) でAPI引数説明不足が判明。",
    "linked_files": ["pkg/indexer/README.md"],
    "owner_hint": "unassigned",
    "acceptance_criteria": "CIでREADME lintチェックが通り、レビューコメントがクローズされる。",
    "status": "open"
  }
]
```

---

## 10. 実装ガイドライン

### 10.1 技術選択の自由度

本設計書は原則と要件を定義するものであり、以下の点で実装者に自由度を与える:

- **言語パーサーの選択**: 対象言語に最適なパーサーを選択してよい
- **グラフデータベースの選択**: 依存関係グラフの保存にはNeo4j、PostgreSQL、インメモリ構造など任意のストレージを使用してよい
- **LLMプロバイダーの選択**: OpenAI、Anthropic、ローカルモデルなど、要件を満たす任意のLLMを使用してよい
- **並列化戦略**: バッチ処理の並列度、キューイング方式は実装環境に応じて最適化してよい

### 10.2 段階的実装

すべての機能を一度に実装する必要はない。以下の優先順位で段階的に実装してもよい:

1. **Phase 1**: 基本チャンキング + 構造メタデータ抽出 + Embedding生成
2. **Phase 2**: 階層的チャンキング + 依存関係抽出 + カバレッジマップ
3. **Phase 3**: LLMによる要約生成 + ドメイン分類
4. **Phase 4**: 品質フィードバックループ + 自動アクション生成

### 10.3 テスト戦略

実装者は以下のテストを実施すること:

- **単体テスト**: チャンカー、メタデータ抽出器、コンテキストビルダーの各コンポーネント
- **統合テスト**: エンドツーエンドのインジェストパイプライン
- **品質テスト**: 実際のリポジトリでインデックスを生成し、検索精度を評価
- **パフォーマンステスト**: 大規模リポジトリ(10万行以上)での処理時間・メモリ使用量を測定

### 10.4 監視とロギング

本番環境では以下の監視を実装すること:

- インジェスト処理の成功率・失敗率
- 各フェーズの処理時間(p50, p95, p99)
- LLM APIコールの回数・トークン数・コスト
- 生成されたチャンクの品質メトリクス分布

---

## 11. 参考資料

- [RAG高精度化プラン](./high-precision-rag-plan.md)
- [RAG検索最適化設計](./rag-retrieval-optimization.md)
- 各言語パーサーのドキュメント(go/ast, tree-sitter, @babel/parser等)
- tiktoken: https://github.com/openai/tiktoken
- OpenAI Embeddings API: https://platform.openai.com/docs/guides/embeddings
