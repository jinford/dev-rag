// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: chunks.sql

package sqlc

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
)

const countStaleChunks = `-- name: CountStaleChunks :one
SELECT COUNT(*) as stale_count
FROM chunks c
WHERE c.is_latest = true
  AND c.git_commit_hash IS NOT NULL
  AND c.indexed_at < NOW() - INTERVAL '1 day' * $1
`

// 指定日数以上古いチャンクの数を取得
func (q *Queries) CountStaleChunks(ctx context.Context, dollar_1 interface{}) (int64, error) {
	row := q.db.QueryRow(ctx, countStaleChunks, dollar_1)
	var stale_count int64
	err := row.Scan(&stale_count)
	return stale_count, err
}

const createChunk = `-- name: CreateChunk :one
INSERT INTO chunks (
    file_id, ordinal, start_line, end_line, content, content_hash, token_count,
    chunk_type, chunk_name, parent_name, signature, doc_comment, imports, calls,
    lines_of_code, comment_ratio, cyclomatic_complexity, embedding_context,
    level, importance_score,
    standard_imports, external_imports, internal_calls, external_calls, type_dependencies,
    source_snapshot_id, git_commit_hash, author, updated_at, indexed_at,
    file_version, is_latest, chunk_key
)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23, $24, $25, $26, $27, $28, $29, $30, $31, $32, $33)
RETURNING id, file_id, ordinal, start_line, end_line, content, content_hash, token_count, chunk_type, chunk_name, parent_name, signature, doc_comment, imports, calls, lines_of_code, comment_ratio, cyclomatic_complexity, embedding_context, level, importance_score, standard_imports, external_imports, internal_calls, external_calls, type_dependencies, source_snapshot_id, git_commit_hash, author, updated_at, indexed_at, file_version, is_latest, chunk_key, created_at
`

type CreateChunkParams struct {
	FileID               pgtype.UUID      `json:"file_id"`
	Ordinal              int32            `json:"ordinal"`
	StartLine            int32            `json:"start_line"`
	EndLine              int32            `json:"end_line"`
	Content              string           `json:"content"`
	ContentHash          string           `json:"content_hash"`
	TokenCount           pgtype.Int4      `json:"token_count"`
	ChunkType            pgtype.Text      `json:"chunk_type"`
	ChunkName            pgtype.Text      `json:"chunk_name"`
	ParentName           pgtype.Text      `json:"parent_name"`
	Signature            pgtype.Text      `json:"signature"`
	DocComment           pgtype.Text      `json:"doc_comment"`
	Imports              []byte           `json:"imports"`
	Calls                []byte           `json:"calls"`
	LinesOfCode          pgtype.Int4      `json:"lines_of_code"`
	CommentRatio         pgtype.Numeric   `json:"comment_ratio"`
	CyclomaticComplexity pgtype.Int4      `json:"cyclomatic_complexity"`
	EmbeddingContext     pgtype.Text      `json:"embedding_context"`
	Level                int32            `json:"level"`
	ImportanceScore      pgtype.Numeric   `json:"importance_score"`
	StandardImports      []byte           `json:"standard_imports"`
	ExternalImports      []byte           `json:"external_imports"`
	InternalCalls        []byte           `json:"internal_calls"`
	ExternalCalls        []byte           `json:"external_calls"`
	TypeDependencies     []byte           `json:"type_dependencies"`
	SourceSnapshotID     pgtype.UUID      `json:"source_snapshot_id"`
	GitCommitHash        pgtype.Text      `json:"git_commit_hash"`
	Author               pgtype.Text      `json:"author"`
	UpdatedAt            pgtype.Timestamp `json:"updated_at"`
	IndexedAt            pgtype.Timestamp `json:"indexed_at"`
	FileVersion          pgtype.Text      `json:"file_version"`
	IsLatest             bool             `json:"is_latest"`
	ChunkKey             string           `json:"chunk_key"`
}

func (q *Queries) CreateChunk(ctx context.Context, arg CreateChunkParams) (Chunk, error) {
	row := q.db.QueryRow(ctx, createChunk,
		arg.FileID,
		arg.Ordinal,
		arg.StartLine,
		arg.EndLine,
		arg.Content,
		arg.ContentHash,
		arg.TokenCount,
		arg.ChunkType,
		arg.ChunkName,
		arg.ParentName,
		arg.Signature,
		arg.DocComment,
		arg.Imports,
		arg.Calls,
		arg.LinesOfCode,
		arg.CommentRatio,
		arg.CyclomaticComplexity,
		arg.EmbeddingContext,
		arg.Level,
		arg.ImportanceScore,
		arg.StandardImports,
		arg.ExternalImports,
		arg.InternalCalls,
		arg.ExternalCalls,
		arg.TypeDependencies,
		arg.SourceSnapshotID,
		arg.GitCommitHash,
		arg.Author,
		arg.UpdatedAt,
		arg.IndexedAt,
		arg.FileVersion,
		arg.IsLatest,
		arg.ChunkKey,
	)
	var i Chunk
	err := row.Scan(
		&i.ID,
		&i.FileID,
		&i.Ordinal,
		&i.StartLine,
		&i.EndLine,
		&i.Content,
		&i.ContentHash,
		&i.TokenCount,
		&i.ChunkType,
		&i.ChunkName,
		&i.ParentName,
		&i.Signature,
		&i.DocComment,
		&i.Imports,
		&i.Calls,
		&i.LinesOfCode,
		&i.CommentRatio,
		&i.CyclomaticComplexity,
		&i.EmbeddingContext,
		&i.Level,
		&i.ImportanceScore,
		&i.StandardImports,
		&i.ExternalImports,
		&i.InternalCalls,
		&i.ExternalCalls,
		&i.TypeDependencies,
		&i.SourceSnapshotID,
		&i.GitCommitHash,
		&i.Author,
		&i.UpdatedAt,
		&i.IndexedAt,
		&i.FileVersion,
		&i.IsLatest,
		&i.ChunkKey,
		&i.CreatedAt,
	)
	return i, err
}

const deleteChunk = `-- name: DeleteChunk :exec
DELETE FROM chunks
WHERE id = $1
`

func (q *Queries) DeleteChunk(ctx context.Context, id pgtype.UUID) error {
	_, err := q.db.Exec(ctx, deleteChunk, id)
	return err
}

const deleteChunksByFile = `-- name: DeleteChunksByFile :exec
DELETE FROM chunks
WHERE file_id = $1
`

func (q *Queries) DeleteChunksByFile(ctx context.Context, fileID pgtype.UUID) error {
	_, err := q.db.Exec(ctx, deleteChunksByFile, fileID)
	return err
}

const findChunksByContentHash = `-- name: FindChunksByContentHash :many
SELECT id, file_id, ordinal, start_line, end_line, content, content_hash, token_count, chunk_type, chunk_name, parent_name, signature, doc_comment, imports, calls, lines_of_code, comment_ratio, cyclomatic_complexity, embedding_context, level, importance_score, standard_imports, external_imports, internal_calls, external_calls, type_dependencies, source_snapshot_id, git_commit_hash, author, updated_at, indexed_at, file_version, is_latest, chunk_key, created_at FROM chunks
WHERE content_hash = $1
ORDER BY created_at DESC
`

func (q *Queries) FindChunksByContentHash(ctx context.Context, contentHash string) ([]Chunk, error) {
	rows, err := q.db.Query(ctx, findChunksByContentHash, contentHash)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Chunk{}
	for rows.Next() {
		var i Chunk
		if err := rows.Scan(
			&i.ID,
			&i.FileID,
			&i.Ordinal,
			&i.StartLine,
			&i.EndLine,
			&i.Content,
			&i.ContentHash,
			&i.TokenCount,
			&i.ChunkType,
			&i.ChunkName,
			&i.ParentName,
			&i.Signature,
			&i.DocComment,
			&i.Imports,
			&i.Calls,
			&i.LinesOfCode,
			&i.CommentRatio,
			&i.CyclomaticComplexity,
			&i.EmbeddingContext,
			&i.Level,
			&i.ImportanceScore,
			&i.StandardImports,
			&i.ExternalImports,
			&i.InternalCalls,
			&i.ExternalCalls,
			&i.TypeDependencies,
			&i.SourceSnapshotID,
			&i.GitCommitHash,
			&i.Author,
			&i.UpdatedAt,
			&i.IndexedAt,
			&i.FileVersion,
			&i.IsLatest,
			&i.ChunkKey,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getChunk = `-- name: GetChunk :one
SELECT id, file_id, ordinal, start_line, end_line, content, content_hash, token_count, chunk_type, chunk_name, parent_name, signature, doc_comment, imports, calls, lines_of_code, comment_ratio, cyclomatic_complexity, embedding_context, level, importance_score, standard_imports, external_imports, internal_calls, external_calls, type_dependencies, source_snapshot_id, git_commit_hash, author, updated_at, indexed_at, file_version, is_latest, chunk_key, created_at FROM chunks
WHERE id = $1
`

func (q *Queries) GetChunk(ctx context.Context, id pgtype.UUID) (Chunk, error) {
	row := q.db.QueryRow(ctx, getChunk, id)
	var i Chunk
	err := row.Scan(
		&i.ID,
		&i.FileID,
		&i.Ordinal,
		&i.StartLine,
		&i.EndLine,
		&i.Content,
		&i.ContentHash,
		&i.TokenCount,
		&i.ChunkType,
		&i.ChunkName,
		&i.ParentName,
		&i.Signature,
		&i.DocComment,
		&i.Imports,
		&i.Calls,
		&i.LinesOfCode,
		&i.CommentRatio,
		&i.CyclomaticComplexity,
		&i.EmbeddingContext,
		&i.Level,
		&i.ImportanceScore,
		&i.StandardImports,
		&i.ExternalImports,
		&i.InternalCalls,
		&i.ExternalCalls,
		&i.TypeDependencies,
		&i.SourceSnapshotID,
		&i.GitCommitHash,
		&i.Author,
		&i.UpdatedAt,
		&i.IndexedAt,
		&i.FileVersion,
		&i.IsLatest,
		&i.ChunkKey,
		&i.CreatedAt,
	)
	return i, err
}

const getChunksWithGitInfo = `-- name: GetChunksWithGitInfo :many

SELECT
    c.id,
    c.chunk_key,
    c.git_commit_hash,
    c.updated_at,
    c.indexed_at,
    c.is_latest,
    f.path as file_path
FROM chunks c
INNER JOIN files f ON c.file_id = f.id
WHERE c.is_latest = true
  AND c.git_commit_hash IS NOT NULL
ORDER BY c.indexed_at DESC
`

type GetChunksWithGitInfoRow struct {
	ID            pgtype.UUID      `json:"id"`
	ChunkKey      string           `json:"chunk_key"`
	GitCommitHash pgtype.Text      `json:"git_commit_hash"`
	UpdatedAt     pgtype.Timestamp `json:"updated_at"`
	IndexedAt     pgtype.Timestamp `json:"indexed_at"`
	IsLatest      bool             `json:"is_latest"`
	FilePath      string           `json:"file_path"`
}

// インデックス鮮度の監視用クエリ
// 鮮度チェックのためにgit_commit_hash付きチャンクを取得
func (q *Queries) GetChunksWithGitInfo(ctx context.Context) ([]GetChunksWithGitInfoRow, error) {
	rows, err := q.db.Query(ctx, getChunksWithGitInfo)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []GetChunksWithGitInfoRow{}
	for rows.Next() {
		var i GetChunksWithGitInfoRow
		if err := rows.Scan(
			&i.ID,
			&i.ChunkKey,
			&i.GitCommitHash,
			&i.UpdatedAt,
			&i.IndexedAt,
			&i.IsLatest,
			&i.FilePath,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getStaleChunks = `-- name: GetStaleChunks :many
SELECT
    c.id,
    c.chunk_key,
    c.git_commit_hash,
    c.updated_at,
    c.indexed_at,
    c.is_latest,
    f.path as file_path
FROM chunks c
INNER JOIN files f ON c.file_id = f.id
WHERE c.is_latest = true
  AND c.git_commit_hash IS NOT NULL
  AND c.indexed_at < NOW() - INTERVAL '1 day' * $1
ORDER BY c.indexed_at ASC
`

type GetStaleChunksRow struct {
	ID            pgtype.UUID      `json:"id"`
	ChunkKey      string           `json:"chunk_key"`
	GitCommitHash pgtype.Text      `json:"git_commit_hash"`
	UpdatedAt     pgtype.Timestamp `json:"updated_at"`
	IndexedAt     pgtype.Timestamp `json:"indexed_at"`
	IsLatest      bool             `json:"is_latest"`
	FilePath      string           `json:"file_path"`
}

// 指定日数以上古いチャンクを取得
func (q *Queries) GetStaleChunks(ctx context.Context, dollar_1 interface{}) ([]GetStaleChunksRow, error) {
	rows, err := q.db.Query(ctx, getStaleChunks, dollar_1)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []GetStaleChunksRow{}
	for rows.Next() {
		var i GetStaleChunksRow
		if err := rows.Scan(
			&i.ID,
			&i.ChunkKey,
			&i.GitCommitHash,
			&i.UpdatedAt,
			&i.IndexedAt,
			&i.IsLatest,
			&i.FilePath,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listChunksByFile = `-- name: ListChunksByFile :many
SELECT id, file_id, ordinal, start_line, end_line, content, content_hash, token_count, chunk_type, chunk_name, parent_name, signature, doc_comment, imports, calls, lines_of_code, comment_ratio, cyclomatic_complexity, embedding_context, level, importance_score, standard_imports, external_imports, internal_calls, external_calls, type_dependencies, source_snapshot_id, git_commit_hash, author, updated_at, indexed_at, file_version, is_latest, chunk_key, created_at FROM chunks
WHERE file_id = $1
ORDER BY ordinal
`

func (q *Queries) ListChunksByFile(ctx context.Context, fileID pgtype.UUID) ([]Chunk, error) {
	rows, err := q.db.Query(ctx, listChunksByFile, fileID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Chunk{}
	for rows.Next() {
		var i Chunk
		if err := rows.Scan(
			&i.ID,
			&i.FileID,
			&i.Ordinal,
			&i.StartLine,
			&i.EndLine,
			&i.Content,
			&i.ContentHash,
			&i.TokenCount,
			&i.ChunkType,
			&i.ChunkName,
			&i.ParentName,
			&i.Signature,
			&i.DocComment,
			&i.Imports,
			&i.Calls,
			&i.LinesOfCode,
			&i.CommentRatio,
			&i.CyclomaticComplexity,
			&i.EmbeddingContext,
			&i.Level,
			&i.ImportanceScore,
			&i.StandardImports,
			&i.ExternalImports,
			&i.InternalCalls,
			&i.ExternalCalls,
			&i.TypeDependencies,
			&i.SourceSnapshotID,
			&i.GitCommitHash,
			&i.Author,
			&i.UpdatedAt,
			&i.IndexedAt,
			&i.FileVersion,
			&i.IsLatest,
			&i.ChunkKey,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listChunksByOrdinalRange = `-- name: ListChunksByOrdinalRange :many
SELECT id, file_id, ordinal, start_line, end_line, content, content_hash, token_count, chunk_type, chunk_name, parent_name, signature, doc_comment, imports, calls, lines_of_code, comment_ratio, cyclomatic_complexity, embedding_context, level, importance_score, standard_imports, external_imports, internal_calls, external_calls, type_dependencies, source_snapshot_id, git_commit_hash, author, updated_at, indexed_at, file_version, is_latest, chunk_key, created_at FROM chunks
WHERE file_id = $1 AND ordinal BETWEEN $2 AND $3
ORDER BY ordinal
`

type ListChunksByOrdinalRangeParams struct {
	FileID    pgtype.UUID `json:"file_id"`
	Ordinal   int32       `json:"ordinal"`
	Ordinal_2 int32       `json:"ordinal_2"`
}

func (q *Queries) ListChunksByOrdinalRange(ctx context.Context, arg ListChunksByOrdinalRangeParams) ([]Chunk, error) {
	rows, err := q.db.Query(ctx, listChunksByOrdinalRange, arg.FileID, arg.Ordinal, arg.Ordinal_2)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Chunk{}
	for rows.Next() {
		var i Chunk
		if err := rows.Scan(
			&i.ID,
			&i.FileID,
			&i.Ordinal,
			&i.StartLine,
			&i.EndLine,
			&i.Content,
			&i.ContentHash,
			&i.TokenCount,
			&i.ChunkType,
			&i.ChunkName,
			&i.ParentName,
			&i.Signature,
			&i.DocComment,
			&i.Imports,
			&i.Calls,
			&i.LinesOfCode,
			&i.CommentRatio,
			&i.CyclomaticComplexity,
			&i.EmbeddingContext,
			&i.Level,
			&i.ImportanceScore,
			&i.StandardImports,
			&i.ExternalImports,
			&i.InternalCalls,
			&i.ExternalCalls,
			&i.TypeDependencies,
			&i.SourceSnapshotID,
			&i.GitCommitHash,
			&i.Author,
			&i.UpdatedAt,
			&i.IndexedAt,
			&i.FileVersion,
			&i.IsLatest,
			&i.ChunkKey,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const updateChunkImportanceScore = `-- name: UpdateChunkImportanceScore :exec
UPDATE chunks
SET importance_score = $2
WHERE id = $1
`

type UpdateChunkImportanceScoreParams struct {
	ID              pgtype.UUID    `json:"id"`
	ImportanceScore pgtype.Numeric `json:"importance_score"`
}

func (q *Queries) UpdateChunkImportanceScore(ctx context.Context, arg UpdateChunkImportanceScoreParams) error {
	_, err := q.db.Exec(ctx, updateChunkImportanceScore, arg.ID, arg.ImportanceScore)
	return err
}
