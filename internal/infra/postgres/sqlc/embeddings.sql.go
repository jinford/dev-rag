// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: embeddings.sql

package sqlc

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
	pgvector_go "github.com/pgvector/pgvector-go"
)

const createEmbedding = `-- name: CreateEmbedding :one
INSERT INTO embeddings (chunk_id, vector, model)
VALUES ($1, $2, $3)
RETURNING chunk_id, vector, model, created_at
`

type CreateEmbeddingParams struct {
	ChunkID pgtype.UUID        `json:"chunk_id"`
	Vector  pgvector_go.Vector `json:"vector"`
	Model   string             `json:"model"`
}

func (q *Queries) CreateEmbedding(ctx context.Context, arg CreateEmbeddingParams) (Embedding, error) {
	row := q.db.QueryRow(ctx, createEmbedding, arg.ChunkID, arg.Vector, arg.Model)
	var i Embedding
	err := row.Scan(
		&i.ChunkID,
		&i.Vector,
		&i.Model,
		&i.CreatedAt,
	)
	return i, err
}

const deleteEmbedding = `-- name: DeleteEmbedding :exec
DELETE FROM embeddings
WHERE chunk_id = $1
`

func (q *Queries) DeleteEmbedding(ctx context.Context, chunkID pgtype.UUID) error {
	_, err := q.db.Exec(ctx, deleteEmbedding, chunkID)
	return err
}

const getEmbedding = `-- name: GetEmbedding :one
SELECT chunk_id, vector, model, created_at FROM embeddings
WHERE chunk_id = $1
`

func (q *Queries) GetEmbedding(ctx context.Context, chunkID pgtype.UUID) (Embedding, error) {
	row := q.db.QueryRow(ctx, getEmbedding, chunkID)
	var i Embedding
	err := row.Scan(
		&i.ChunkID,
		&i.Vector,
		&i.Model,
		&i.CreatedAt,
	)
	return i, err
}

const searchChunksByProduct = `-- name: SearchChunksByProduct :many
WITH latest_snapshots AS (
    SELECT DISTINCT ON (source_id) id, source_id
    FROM source_snapshots
    WHERE indexed = TRUE
    ORDER BY source_id, indexed_at DESC NULLS LAST, created_at DESC
)
SELECT
    c.id AS chunk_id,
    f.path,
    c.start_line,
    c.end_line,
    c.content,
    (1::float8 - (e.vector <=> $1::vector))::float8 AS score
FROM embeddings e
INNER JOIN chunks c ON e.chunk_id = c.id
INNER JOIN files f ON c.file_id = f.id
INNER JOIN latest_snapshots ls ON f.snapshot_id = ls.id
INNER JOIN sources s ON ls.source_id = s.id
WHERE s.product_id = $2
  AND ($3::text IS NULL OR f.path LIKE ($3::text || '%'))
  AND ($4::text IS NULL OR f.content_type = $4::text)
ORDER BY e.vector <=> $1::vector
LIMIT $5
`

type SearchChunksByProductParams struct {
	QueryVector pgvector_go.Vector `json:"query_vector"`
	ProductID   pgtype.UUID        `json:"product_id"`
	PathPrefix  pgtype.Text        `json:"path_prefix"`
	ContentType pgtype.Text        `json:"content_type"`
	RowLimit    int32              `json:"row_limit"`
}

type SearchChunksByProductRow struct {
	ChunkID   pgtype.UUID `json:"chunk_id"`
	Path      string      `json:"path"`
	StartLine int32       `json:"start_line"`
	EndLine   int32       `json:"end_line"`
	Content   string      `json:"content"`
	Score     float64     `json:"score"`
}

func (q *Queries) SearchChunksByProduct(ctx context.Context, arg SearchChunksByProductParams) ([]SearchChunksByProductRow, error) {
	rows, err := q.db.Query(ctx, searchChunksByProduct,
		arg.QueryVector,
		arg.ProductID,
		arg.PathPrefix,
		arg.ContentType,
		arg.RowLimit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []SearchChunksByProductRow{}
	for rows.Next() {
		var i SearchChunksByProductRow
		if err := rows.Scan(
			&i.ChunkID,
			&i.Path,
			&i.StartLine,
			&i.EndLine,
			&i.Content,
			&i.Score,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchChunksBySnapshot = `-- name: SearchChunksBySnapshot :many
SELECT
    c.id AS chunk_id,
    f.path,
    c.start_line,
    c.end_line,
    c.content,
    (1 - (e.vector <=> $1::vector))::float8 AS score
FROM chunks c
JOIN files f ON c.file_id = f.id
JOIN embeddings e ON c.id = e.chunk_id
WHERE f.snapshot_id = $2
  AND ($3::text IS NULL OR f.path LIKE $3::text || '%')
  AND ($4::text IS NULL OR f.content_type = $4::text)
ORDER BY e.vector <=> $1::vector
LIMIT $5
`

type SearchChunksBySnapshotParams struct {
	QueryVector pgvector_go.Vector `json:"query_vector"`
	SnapshotID  pgtype.UUID        `json:"snapshot_id"`
	PathPrefix  pgtype.Text        `json:"path_prefix"`
	ContentType pgtype.Text        `json:"content_type"`
	LimitVal    int32              `json:"limit_val"`
}

type SearchChunksBySnapshotRow struct {
	ChunkID   pgtype.UUID `json:"chunk_id"`
	Path      string      `json:"path"`
	StartLine int32       `json:"start_line"`
	EndLine   int32       `json:"end_line"`
	Content   string      `json:"content"`
	Score     float64     `json:"score"`
}

func (q *Queries) SearchChunksBySnapshot(ctx context.Context, arg SearchChunksBySnapshotParams) ([]SearchChunksBySnapshotRow, error) {
	rows, err := q.db.Query(ctx, searchChunksBySnapshot,
		arg.QueryVector,
		arg.SnapshotID,
		arg.PathPrefix,
		arg.ContentType,
		arg.LimitVal,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []SearchChunksBySnapshotRow{}
	for rows.Next() {
		var i SearchChunksBySnapshotRow
		if err := rows.Scan(
			&i.ChunkID,
			&i.Path,
			&i.StartLine,
			&i.EndLine,
			&i.Content,
			&i.Score,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchChunksBySource = `-- name: SearchChunksBySource :many
WITH latest_snapshot AS (
    SELECT id
    FROM source_snapshots
    WHERE source_id = $5
      AND indexed = TRUE
    ORDER BY indexed_at DESC NULLS LAST, created_at DESC
    LIMIT 1
)
SELECT
    c.id AS chunk_id,
    f.path,
    c.start_line,
    c.end_line,
    c.content,
    (1::float8 - (e.vector <=> $1::vector))::float8 AS score
FROM embeddings e
INNER JOIN chunks c ON e.chunk_id = c.id
INNER JOIN files f ON c.file_id = f.id
INNER JOIN latest_snapshot ls ON f.snapshot_id = ls.id
WHERE ($2::text IS NULL OR f.path LIKE ($2::text || '%'))
  AND ($3::text IS NULL OR f.content_type = $3::text)
ORDER BY e.vector <=> $1::vector
LIMIT $4
`

type SearchChunksBySourceParams struct {
	QueryVector pgvector_go.Vector `json:"query_vector"`
	PathPrefix  pgtype.Text        `json:"path_prefix"`
	ContentType pgtype.Text        `json:"content_type"`
	RowLimit    int32              `json:"row_limit"`
	SourceID    pgtype.UUID        `json:"source_id"`
}

type SearchChunksBySourceRow struct {
	ChunkID   pgtype.UUID `json:"chunk_id"`
	Path      string      `json:"path"`
	StartLine int32       `json:"start_line"`
	EndLine   int32       `json:"end_line"`
	Content   string      `json:"content"`
	Score     float64     `json:"score"`
}

func (q *Queries) SearchChunksBySource(ctx context.Context, arg SearchChunksBySourceParams) ([]SearchChunksBySourceRow, error) {
	rows, err := q.db.Query(ctx, searchChunksBySource,
		arg.QueryVector,
		arg.PathPrefix,
		arg.ContentType,
		arg.RowLimit,
		arg.SourceID,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []SearchChunksBySourceRow{}
	for rows.Next() {
		var i SearchChunksBySourceRow
		if err := rows.Scan(
			&i.ChunkID,
			&i.Path,
			&i.StartLine,
			&i.EndLine,
			&i.Content,
			&i.Score,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchSimilarChunks = `-- name: SearchSimilarChunks :many
SELECT
    e.chunk_id,
    e.vector,
    e.model,
    e.created_at,
    1 - (e.vector <=> $1::vector) as similarity
FROM embeddings e
ORDER BY e.vector <=> $1::vector
LIMIT $2
`

type SearchSimilarChunksParams struct {
	Column1 pgvector_go.Vector `json:"column_1"`
	Limit   int32              `json:"limit"`
}

type SearchSimilarChunksRow struct {
	ChunkID    pgtype.UUID        `json:"chunk_id"`
	Vector     pgvector_go.Vector `json:"vector"`
	Model      string             `json:"model"`
	CreatedAt  pgtype.Timestamp   `json:"created_at"`
	Similarity int32              `json:"similarity"`
}

func (q *Queries) SearchSimilarChunks(ctx context.Context, arg SearchSimilarChunksParams) ([]SearchSimilarChunksRow, error) {
	rows, err := q.db.Query(ctx, searchSimilarChunks, arg.Column1, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []SearchSimilarChunksRow{}
	for rows.Next() {
		var i SearchSimilarChunksRow
		if err := rows.Scan(
			&i.ChunkID,
			&i.Vector,
			&i.Model,
			&i.CreatedAt,
			&i.Similarity,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
