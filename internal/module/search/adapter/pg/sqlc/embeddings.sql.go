// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: embeddings.sql

package sqlc

import (
	"context"

	"github.com/jackc/pgx/v5/pgtype"
	pgvector_go "github.com/pgvector/pgvector-go"
)

const createEmbedding = `-- name: CreateEmbedding :one
INSERT INTO embeddings (chunk_id, vector, model)
VALUES ($1, $2, $3)
RETURNING chunk_id, vector, model, created_at
`

type CreateEmbeddingParams struct {
	ChunkID pgtype.UUID        `json:"chunk_id"`
	Vector  pgvector_go.Vector `json:"vector"`
	Model   string             `json:"model"`
}

func (q *Queries) CreateEmbedding(ctx context.Context, arg CreateEmbeddingParams) (Embedding, error) {
	row := q.db.QueryRow(ctx, createEmbedding, arg.ChunkID, arg.Vector, arg.Model)
	var i Embedding
	err := row.Scan(
		&i.ChunkID,
		&i.Vector,
		&i.Model,
		&i.CreatedAt,
	)
	return i, err
}

const deleteEmbedding = `-- name: DeleteEmbedding :exec
DELETE FROM embeddings
WHERE chunk_id = $1
`

func (q *Queries) DeleteEmbedding(ctx context.Context, chunkID pgtype.UUID) error {
	_, err := q.db.Exec(ctx, deleteEmbedding, chunkID)
	return err
}

const getChildChunks = `-- name: GetChildChunks :many
SELECT c.id, c.file_id, c.ordinal, c.start_line, c.end_line, c.content, c.content_hash, c.token_count, c.chunk_type, c.chunk_name, c.parent_name, c.signature, c.doc_comment, c.imports, c.calls, c.lines_of_code, c.comment_ratio, c.cyclomatic_complexity, c.embedding_context, c.level, c.importance_score, c.standard_imports, c.external_imports, c.internal_calls, c.external_calls, c.type_dependencies, c.source_snapshot_id, c.git_commit_hash, c.author, c.updated_at, c.indexed_at, c.file_version, c.is_latest, c.chunk_key, c.created_at
FROM chunks c
INNER JOIN chunk_hierarchy ch ON c.id = ch.child_chunk_id
WHERE ch.parent_chunk_id = $1
ORDER BY ch.ordinal
`

func (q *Queries) GetChildChunks(ctx context.Context, parentChunkID pgtype.UUID) ([]Chunk, error) {
	rows, err := q.db.Query(ctx, getChildChunks, parentChunkID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Chunk{}
	for rows.Next() {
		var i Chunk
		if err := rows.Scan(
			&i.ID,
			&i.FileID,
			&i.Ordinal,
			&i.StartLine,
			&i.EndLine,
			&i.Content,
			&i.ContentHash,
			&i.TokenCount,
			&i.ChunkType,
			&i.ChunkName,
			&i.ParentName,
			&i.Signature,
			&i.DocComment,
			&i.Imports,
			&i.Calls,
			&i.LinesOfCode,
			&i.CommentRatio,
			&i.CyclomaticComplexity,
			&i.EmbeddingContext,
			&i.Level,
			&i.ImportanceScore,
			&i.StandardImports,
			&i.ExternalImports,
			&i.InternalCalls,
			&i.ExternalCalls,
			&i.TypeDependencies,
			&i.SourceSnapshotID,
			&i.GitCommitHash,
			&i.Author,
			&i.UpdatedAt,
			&i.IndexedAt,
			&i.FileVersion,
			&i.IsLatest,
			&i.ChunkKey,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getChunk = `-- name: GetChunk :one
SELECT id, file_id, ordinal, start_line, end_line, content, content_hash, token_count, chunk_type, chunk_name, parent_name, signature, doc_comment, imports, calls, lines_of_code, comment_ratio, cyclomatic_complexity, embedding_context, level, importance_score, standard_imports, external_imports, internal_calls, external_calls, type_dependencies, source_snapshot_id, git_commit_hash, author, updated_at, indexed_at, file_version, is_latest, chunk_key, created_at FROM chunks
WHERE id = $1
`

func (q *Queries) GetChunk(ctx context.Context, id pgtype.UUID) (Chunk, error) {
	row := q.db.QueryRow(ctx, getChunk, id)
	var i Chunk
	err := row.Scan(
		&i.ID,
		&i.FileID,
		&i.Ordinal,
		&i.StartLine,
		&i.EndLine,
		&i.Content,
		&i.ContentHash,
		&i.TokenCount,
		&i.ChunkType,
		&i.ChunkName,
		&i.ParentName,
		&i.Signature,
		&i.DocComment,
		&i.Imports,
		&i.Calls,
		&i.LinesOfCode,
		&i.CommentRatio,
		&i.CyclomaticComplexity,
		&i.EmbeddingContext,
		&i.Level,
		&i.ImportanceScore,
		&i.StandardImports,
		&i.ExternalImports,
		&i.InternalCalls,
		&i.ExternalCalls,
		&i.TypeDependencies,
		&i.SourceSnapshotID,
		&i.GitCommitHash,
		&i.Author,
		&i.UpdatedAt,
		&i.IndexedAt,
		&i.FileVersion,
		&i.IsLatest,
		&i.ChunkKey,
		&i.CreatedAt,
	)
	return i, err
}

const getEmbedding = `-- name: GetEmbedding :one
SELECT chunk_id, vector, model, created_at FROM embeddings
WHERE chunk_id = $1
`

func (q *Queries) GetEmbedding(ctx context.Context, chunkID pgtype.UUID) (Embedding, error) {
	row := q.db.QueryRow(ctx, getEmbedding, chunkID)
	var i Embedding
	err := row.Scan(
		&i.ChunkID,
		&i.Vector,
		&i.Model,
		&i.CreatedAt,
	)
	return i, err
}

const getParentChunk = `-- name: GetParentChunk :one
SELECT c.id, c.file_id, c.ordinal, c.start_line, c.end_line, c.content, c.content_hash, c.token_count, c.chunk_type, c.chunk_name, c.parent_name, c.signature, c.doc_comment, c.imports, c.calls, c.lines_of_code, c.comment_ratio, c.cyclomatic_complexity, c.embedding_context, c.level, c.importance_score, c.standard_imports, c.external_imports, c.internal_calls, c.external_calls, c.type_dependencies, c.source_snapshot_id, c.git_commit_hash, c.author, c.updated_at, c.indexed_at, c.file_version, c.is_latest, c.chunk_key, c.created_at
FROM chunks c
INNER JOIN chunk_hierarchy ch ON c.id = ch.parent_chunk_id
WHERE ch.child_chunk_id = $1
LIMIT 1
`

func (q *Queries) GetParentChunk(ctx context.Context, childChunkID pgtype.UUID) (Chunk, error) {
	row := q.db.QueryRow(ctx, getParentChunk, childChunkID)
	var i Chunk
	err := row.Scan(
		&i.ID,
		&i.FileID,
		&i.Ordinal,
		&i.StartLine,
		&i.EndLine,
		&i.Content,
		&i.ContentHash,
		&i.TokenCount,
		&i.ChunkType,
		&i.ChunkName,
		&i.ParentName,
		&i.Signature,
		&i.DocComment,
		&i.Imports,
		&i.Calls,
		&i.LinesOfCode,
		&i.CommentRatio,
		&i.CyclomaticComplexity,
		&i.EmbeddingContext,
		&i.Level,
		&i.ImportanceScore,
		&i.StandardImports,
		&i.ExternalImports,
		&i.InternalCalls,
		&i.ExternalCalls,
		&i.TypeDependencies,
		&i.SourceSnapshotID,
		&i.GitCommitHash,
		&i.Author,
		&i.UpdatedAt,
		&i.IndexedAt,
		&i.FileVersion,
		&i.IsLatest,
		&i.ChunkKey,
		&i.CreatedAt,
	)
	return i, err
}

const listChunksByOrdinalRange = `-- name: ListChunksByOrdinalRange :many
SELECT id, file_id, ordinal, start_line, end_line, content, content_hash, token_count, chunk_type, chunk_name, parent_name, signature, doc_comment, imports, calls, lines_of_code, comment_ratio, cyclomatic_complexity, embedding_context, level, importance_score, standard_imports, external_imports, internal_calls, external_calls, type_dependencies, source_snapshot_id, git_commit_hash, author, updated_at, indexed_at, file_version, is_latest, chunk_key, created_at FROM chunks
WHERE file_id = $1 AND ordinal BETWEEN $2 AND $3
ORDER BY ordinal
`

type ListChunksByOrdinalRangeParams struct {
	FileID    pgtype.UUID `json:"file_id"`
	Ordinal   int32       `json:"ordinal"`
	Ordinal_2 int32       `json:"ordinal_2"`
}

func (q *Queries) ListChunksByOrdinalRange(ctx context.Context, arg ListChunksByOrdinalRangeParams) ([]Chunk, error) {
	rows, err := q.db.Query(ctx, listChunksByOrdinalRange, arg.FileID, arg.Ordinal, arg.Ordinal_2)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Chunk{}
	for rows.Next() {
		var i Chunk
		if err := rows.Scan(
			&i.ID,
			&i.FileID,
			&i.Ordinal,
			&i.StartLine,
			&i.EndLine,
			&i.Content,
			&i.ContentHash,
			&i.TokenCount,
			&i.ChunkType,
			&i.ChunkName,
			&i.ParentName,
			&i.Signature,
			&i.DocComment,
			&i.Imports,
			&i.Calls,
			&i.LinesOfCode,
			&i.CommentRatio,
			&i.CyclomaticComplexity,
			&i.EmbeddingContext,
			&i.Level,
			&i.ImportanceScore,
			&i.StandardImports,
			&i.ExternalImports,
			&i.InternalCalls,
			&i.ExternalCalls,
			&i.TypeDependencies,
			&i.SourceSnapshotID,
			&i.GitCommitHash,
			&i.Author,
			&i.UpdatedAt,
			&i.IndexedAt,
			&i.FileVersion,
			&i.IsLatest,
			&i.ChunkKey,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchChunksByProduct = `-- name: SearchChunksByProduct :many
WITH latest_snapshots AS (
    SELECT DISTINCT ON (source_id) id, source_id
    FROM source_snapshots
    WHERE indexed = TRUE
    ORDER BY source_id, indexed_at DESC NULLS LAST, created_at DESC
)
SELECT
    c.id AS chunk_id,
    f.path,
    c.start_line,
    c.end_line,
    c.content,
    (1::float8 - (e.vector <=> $1::vector))::float8 AS score
FROM embeddings e
INNER JOIN chunks c ON e.chunk_id = c.id
INNER JOIN files f ON c.file_id = f.id
INNER JOIN latest_snapshots ls ON f.snapshot_id = ls.id
INNER JOIN sources s ON ls.source_id = s.id
WHERE s.product_id = $2
  AND ($3::text IS NULL OR f.path LIKE ($3::text || '%'))
  AND ($4::text IS NULL OR f.content_type = $4::text)
ORDER BY e.vector <=> $1::vector
LIMIT $5
`

type SearchChunksByProductParams struct {
	QueryVector pgvector_go.Vector `json:"query_vector"`
	ProductID   pgtype.UUID        `json:"product_id"`
	PathPrefix  pgtype.Text        `json:"path_prefix"`
	ContentType pgtype.Text        `json:"content_type"`
	RowLimit    int32              `json:"row_limit"`
}

type SearchChunksByProductRow struct {
	ChunkID   pgtype.UUID `json:"chunk_id"`
	Path      string      `json:"path"`
	StartLine int32       `json:"start_line"`
	EndLine   int32       `json:"end_line"`
	Content   string      `json:"content"`
	Score     float64     `json:"score"`
}

func (q *Queries) SearchChunksByProduct(ctx context.Context, arg SearchChunksByProductParams) ([]SearchChunksByProductRow, error) {
	rows, err := q.db.Query(ctx, searchChunksByProduct,
		arg.QueryVector,
		arg.ProductID,
		arg.PathPrefix,
		arg.ContentType,
		arg.RowLimit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []SearchChunksByProductRow{}
	for rows.Next() {
		var i SearchChunksByProductRow
		if err := rows.Scan(
			&i.ChunkID,
			&i.Path,
			&i.StartLine,
			&i.EndLine,
			&i.Content,
			&i.Score,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchChunksBySource = `-- name: SearchChunksBySource :many
WITH latest_snapshot AS (
    SELECT id
    FROM source_snapshots
    WHERE source_id = $5
      AND indexed = TRUE
    ORDER BY indexed_at DESC NULLS LAST, created_at DESC
    LIMIT 1
)
SELECT
    c.id AS chunk_id,
    f.path,
    c.start_line,
    c.end_line,
    c.content,
    (1::float8 - (e.vector <=> $1::vector))::float8 AS score
FROM embeddings e
INNER JOIN chunks c ON e.chunk_id = c.id
INNER JOIN files f ON c.file_id = f.id
INNER JOIN latest_snapshot ls ON f.snapshot_id = ls.id
WHERE ($2::text IS NULL OR f.path LIKE ($2::text || '%'))
  AND ($3::text IS NULL OR f.content_type = $3::text)
ORDER BY e.vector <=> $1::vector
LIMIT $4
`

type SearchChunksBySourceParams struct {
	QueryVector pgvector_go.Vector `json:"query_vector"`
	PathPrefix  pgtype.Text        `json:"path_prefix"`
	ContentType pgtype.Text        `json:"content_type"`
	RowLimit    int32              `json:"row_limit"`
	SourceID    pgtype.UUID        `json:"source_id"`
}

type SearchChunksBySourceRow struct {
	ChunkID   pgtype.UUID `json:"chunk_id"`
	Path      string      `json:"path"`
	StartLine int32       `json:"start_line"`
	EndLine   int32       `json:"end_line"`
	Content   string      `json:"content"`
	Score     float64     `json:"score"`
}

func (q *Queries) SearchChunksBySource(ctx context.Context, arg SearchChunksBySourceParams) ([]SearchChunksBySourceRow, error) {
	rows, err := q.db.Query(ctx, searchChunksBySource,
		arg.QueryVector,
		arg.PathPrefix,
		arg.ContentType,
		arg.RowLimit,
		arg.SourceID,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []SearchChunksBySourceRow{}
	for rows.Next() {
		var i SearchChunksBySourceRow
		if err := rows.Scan(
			&i.ChunkID,
			&i.Path,
			&i.StartLine,
			&i.EndLine,
			&i.Content,
			&i.Score,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchSimilarChunks = `-- name: SearchSimilarChunks :many
SELECT
    e.chunk_id,
    e.vector,
    e.model,
    e.created_at,
    1 - (e.vector <=> $1::vector) as similarity
FROM embeddings e
ORDER BY e.vector <=> $1::vector
LIMIT $2
`

type SearchSimilarChunksParams struct {
	Column1 pgvector_go.Vector `json:"column_1"`
	Limit   int32              `json:"limit"`
}

type SearchSimilarChunksRow struct {
	ChunkID    pgtype.UUID        `json:"chunk_id"`
	Vector     pgvector_go.Vector `json:"vector"`
	Model      string             `json:"model"`
	CreatedAt  pgtype.Timestamp   `json:"created_at"`
	Similarity int32              `json:"similarity"`
}

func (q *Queries) SearchSimilarChunks(ctx context.Context, arg SearchSimilarChunksParams) ([]SearchSimilarChunksRow, error) {
	rows, err := q.db.Query(ctx, searchSimilarChunks, arg.Column1, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []SearchSimilarChunksRow{}
	for rows.Next() {
		var i SearchSimilarChunksRow
		if err := rows.Scan(
			&i.ChunkID,
			&i.Vector,
			&i.Model,
			&i.CreatedAt,
			&i.Similarity,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
